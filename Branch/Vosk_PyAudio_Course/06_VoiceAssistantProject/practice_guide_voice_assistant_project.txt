# PRACTICE GUIDE: VOICE ASSISTANT PROJECT

## OVERVIEW

In this final practice session, you will build a complete voice assistant by integrating all the components developed in previous modules and adding new features such as wake word detection, speech synthesis, and dialog management. The result will be a functional voice assistant that you can customize and extend.

## OBJECTIVES

1. Implement a complete voice assistant with wake word detection
2. Add speech synthesis for verbal responses
3. Create a dialog management system for contextual conversations
4. Build a configuration system for easy customization
5. Implement robust error handling for continuous operation
6. Design and implement domain-specific action handlers

## PREREQUISITES

- Completion of all previous modules (1-5)
- Installation of additional libraries:
  - pyttsx3 (speech synthesis)
  - pvporcupine (wake word detection)
  - requests (for API calls)
  - json (for configuration management)

## PRACTICE EXERCISES

### Exercise 1: Project Structure Setup

1. Create a new directory called `voice_assistant` for your project
2. Set up the following file structure:

```
voice_assistant/
├── config/
│   └── assistant_config.json
├── models/
├── logs/
├── assistant/
│   ├── __init__.py
│   ├── audio_processing.py
│   ├── speech_recognition.py
│   ├── speech_synthesis.py
│   ├── intent_processing.py
│   ├── dialog_manager.py
│   ├── action_handlers.py
│   ├── error_handler.py
│   └── config_manager.py
├── main.py
└── requirements.txt
```

3. Create a `requirements.txt` file with all necessary dependencies:

```
vosk==0.3.32
pyaudio==0.2.11
numpy==1.21.5
pyttsx3==2.90
pvporcupine==2.1.4
requests==2.28.1
```

### Exercise 2: Configuration Management System

1. Create a configuration file at `config/assistant_config.json` with the following content:

```json
{
  "assistant_name": "Assistant",
  "wake_word": "computer",
  "voice_index": 0,
  "speech_rate": 150,
  "volume": 0.8,
  "language": "en-US",
  "log_level": "info",
  "user_name": "User",
  "model_path": "/path/to/vosk/model"
}
```

2. Implement the `ConfigManager` class in `assistant/config_manager.py`:

```python
import json
import os

class ConfigManager:
    def __init__(self, config_file="config/assistant_config.json"):
        # TODO: Implement configuration loading and management
        # 1. Define default configuration
        # 2. Load from file or use defaults
        # 3. Implement get, set, and update methods
        pass
```

### Exercise 3: Error Handling and Logging

1. Implement the error handling system in `assistant/error_handler.py`:

```python
import logging
import traceback
import sys

def setup_logger(name, level=logging.INFO, log_dir='logs'):
    # TODO: Implement logger setup
    # 1. Create logger with appropriate level
    # 2. Add console and file handlers
    # 3. Configure formatters
    pass

class ErrorHandler:
    def __init__(self, logger):
        # TODO: Implement error handling system
        # 1. Initialize with logger
        # 2. Track error counts
        # 3. Implement handle_error method
        # 4. Add recovery suggestion logic
        pass
```

### Exercise 4: Speech Synthesis

1. Implement the speech synthesis system in `assistant/speech_synthesis.py`:

```python
import pyttsx3

class SpeechSynthesizer:
    def __init__(self, config_manager):
        # TODO: Implement speech synthesis
        # 1. Initialize pyttsx3 engine
        # 2. Configure properties from config
        # 3. Implement speak method
        # 4. Add voice and rate adjustment methods
        pass
```

2. Test your speech synthesis with a simple script:

```python
from assistant.speech_synthesis import SpeechSynthesizer
from assistant.config_manager import ConfigManager

# Create config manager and speech synthesizer
config = ConfigManager()
synthesizer = SpeechSynthesizer(config)

# Test speaking
synthesizer.speak("Hello, I am your voice assistant.")

# Test different voices
synthesizer.change_voice(1)
synthesizer.speak("This is a different voice.")

# Test different rates
synthesizer.adjust_rate(200)
synthesizer.speak("This is faster speech.")
synthesizer.adjust_rate(100)
synthesizer.speak("This is slower speech.")
```

### Exercise 5: Wake Word Detection

1. Implement wake word detection in `assistant/audio_processing.py`:

```python
import pvporcupine
import pyaudio
import struct
import threading
import queue
import time

class WakeWordDetector:
    def __init__(self, config_manager, callback):
        # TODO: Implement wake word detection
        # 1. Initialize Porcupine with wake word from config
        # 2. Set up audio stream for detection
        # 3. Create thread for continuous listening
        # 4. Implement detection callback
        pass
        
    def start(self):
        # TODO: Start the detection thread
        pass
        
    def detection_thread(self):
        # TODO: Implement detection loop
        # 1. Read audio frames
        # 2. Process with Porcupine
        # 3. Call callback when wake word detected
        pass
        
    def stop(self):
        # TODO: Stop detection and clean up resources
        pass
```

### Exercise 6: Dialog Management System

1. Implement the dialog manager in `assistant/dialog_manager.py`:

```python
import time

class DialogManager:
    def __init__(self, config_manager):
        # TODO: Implement dialog management system
        # 1. Initialize state tracking
        # 2. Set up conversation history
        # 3. Initialize context tracking
        pass
        
    def process_turn(self, intent, entities):
        # TODO: Process conversation turn
        # 1. Add to conversation history
        # 2. Update context with new entities
        # 3. Handle state-specific processing
        # 4. Return appropriate response or None
        pass
        
    def _handle_new_request(self, intent, entities):
        # TODO: Handle a new user request
        pass
        
    def _handle_follow_up(self, intent, entities):
        # TODO: Handle follow-up in multi-turn conversation
        pass
        
    def clear_context(self):
        # TODO: Reset conversation context
        pass
```

### Exercise 7: Action Handlers for Different Domains

1. Implement action handlers in `assistant/action_handlers.py`:

```python
import time
import random
import requests

class ActionHandlers:
    def __init__(self, speech_synthesizer, config_manager):
        # TODO: Implement action handlers
        # 1. Store dependencies
        # 2. Register handlers for different intents
        # 3. Implement handler methods for each intent
        pass
        
    def handle_intent(self, intent, entities):
        # TODO: Route intent to appropriate handler
        pass
        
    # Implement individual handlers for each intent domain
    def handle_greeting(self, entities):
        # TODO: Implement greeting handler
        pass
        
    def handle_time(self, entities):
        # TODO: Implement time query handler
        pass
        
    def handle_weather(self, entities):
        # TODO: Implement weather query handler
        pass
        
    def handle_timer(self, entities):
        # TODO: Implement timer handler
        pass
        
    # Add more handlers for other domains
```

### Exercise 8: Voice Assistant Integration

1. Create the main voice assistant class in `assistant/__init__.py`:

```python
from .audio_processing import ThreadedAudioProcessor, WakeWordDetector
from .speech_recognition import ThreadedRecognition
from .speech_synthesis import SpeechSynthesizer
from .intent_processing import IntentProcessor
from .dialog_manager import DialogManager
from .action_handlers import ActionHandlers
from .config_manager import ConfigManager
from .error_handler import setup_logger, ErrorHandler
import queue
import time
import sys
import threading

class VoiceAssistant:
    def __init__(self, config_file="config/assistant_config.json"):
        # TODO: Initialize voice assistant
        # 1. Set up logging and error handling
        # 2. Load configuration
        # 3. Initialize all components
        # 4. Set up system state
        pass
        
    def init_components(self):
        # TODO: Initialize all assistant components
        # 1. Create speech synthesizer
        # 2. Set up wake word detection
        # 3. Set up audio processing and recognition
        # 4. Set up dialog and action components
        pass
        
    def on_wake_word_detected(self):
        # TODO: Handle wake word detection
        # 1. Play acknowledgment sound or response
        # 2. Start active listening
        pass
        
    def start(self):
        # TODO: Start the voice assistant
        # 1. Start all components
        # 2. Provide initial greeting
        # 3. Start main loop
        pass
        
    def main_loop(self):
        # TODO: Implement main processing loop
        # 1. Listen for intents
        # 2. Process with dialog manager
        # 3. Execute actions
        # 4. Handle errors
        pass
        
    def stop(self):
        # TODO: Stop all components cleanly
        pass
```

2. Create the main entry point in `main.py`:

```python
from assistant import VoiceAssistant
import sys
import argparse

def main():
    # TODO: Implement main entry point
    # 1. Parse command line arguments
    # 2. Create and start voice assistant
    # 3. Handle interrupts and shutdown
    pass

if __name__ == "__main__":
    sys.exit(main())
```

### Exercise 9: Testing and Improvement

1. Test your voice assistant with various scenarios:
   - Basic questions (time, weather, etc.)
   - Multi-turn conversations
   - Error handling situations
   - Wake word detection accuracy

2. Implement improvements based on your testing:
   - Adjust wake word sensitivity
   - Improve intent recognition patterns
   - Add more sophisticated dialog management
   - Enhance error recovery strategies

### Exercise 10: Choose and Implement Extensions

Choose at least two of the following extensions to implement:

1. **Weather Integration**:
   - Register for a free API key from OpenWeatherMap or similar service
   - Create a weather service that fetches real data
   - Enhance the weather intent handler to use this service

2. **Music Player Control**:
   - Integrate with a local music player (e.g., VLC, MPD)
   - Implement play, pause, next, previous commands
   - Add volume control functionality

3. **Knowledge Base**:
   - Create a simple knowledge base system
   - Implement basic question answering
   - Use Wikipedia API for general knowledge queries

4. **Calendar Integration**:
   - Create a simple calendar system with reminders
   - Implement date and time parsing
   - Add commands to add, view, and delete events

5. **Home Automation**:
   - Simulate or integrate with real home automation devices
   - Add commands for lights, temperature, etc.
   - Implement room-based context ("turn on the lights in the kitchen")

## EXPECTED OUTCOMES

By completing these exercises, you'll have created:

1. A complete voice assistant with wake word detection
2. A system that responds verbally using speech synthesis
3. A contextual dialog management system
4. A modular, extensible architecture
5. At least two domain-specific features (from Exercise 10)

## SUBMISSION GUIDELINES

1. Submit your complete `voice_assistant` directory
2. Include a README.md file with:
   - Installation instructions
   - Features implemented
   - Usage examples
   - Known limitations
   - Future improvements
3. Include a short demo video showing your assistant in action

## NEXT STEPS

Congratulations on completing the Vosk PyAudio Course! Here are some suggestions for continuing your learning journey:

1. **Enhance Your Assistant**: Add more features, improve accuracy, and extend functionality
2. **Deploy Your Assistant**: Create a standalone application or deploy on a dedicated device like Raspberry Pi
3. **Explore Advanced NLP**: Learn about deep learning approaches to NLP for better language understanding
4. **Contribute to Open Source**: Consider contributing to Vosk or other open-source speech projects
5. **Share Your Knowledge**: Create tutorials or blog posts about what you've learned
