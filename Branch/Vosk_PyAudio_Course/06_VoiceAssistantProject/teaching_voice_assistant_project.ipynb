{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2378f78c",
   "metadata": {},
   "source": [
    "# VOICE ASSISTANT PROJECT: PUTTING IT ALL TOGETHER\n",
    "\n",
    "## GLOSSARY\n",
    "\n",
    "- **Voice Assistant**: A software application that uses voice recognition, natural language processing, and speech synthesis to provide services to users\n",
    "- **Project Architecture**: The high-level structure that defines a system's components and their interactions\n",
    "- **Feature Set**: A collection of capabilities or functions that a product offers to its users\n",
    "- **User Experience (UX)**: The overall experience a user has when using a product, especially in terms of how easy or pleasing it is to use\n",
    "- **System Integration**: The process of bringing together different components to form a cohesive, functioning whole\n",
    "- **Continuous Operation**: A system that runs without interruption, handling errors gracefully\n",
    "- **Configuration Management**: The process of handling settings that control a system's behavior\n",
    "- **Dialog Management**: The component that controls conversation flow in a voice assistant\n",
    "- **Action Handling**: The process of executing the appropriate function in response to a recognized intent\n",
    "- **Error Recovery**: The ability of a system to detect, respond to, and recover from unexpected conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a081be4",
   "metadata": {},
   "source": [
    "## CONCEPT INTERACTIONS\n",
    "\n",
    "- **Building on Integration**: We'll use the integrated system from Module 5 as our foundation\n",
    "- **Building on Speech Recognition**: We'll enhance the speech recognition component with wake word detection\n",
    "- **Building on Speech Understanding**: We'll expand the intent recognition capabilities with more sophisticated patterns\n",
    "- **New Concepts**: We'll add speech synthesis, configuration management, and dialog management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bfe2d",
   "metadata": {},
   "source": [
    "## MAIN CONTENT\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "In this final module, we'll create a complete voice assistant that can:\n",
    "\n",
    "1. Listen continuously for a wake word\n",
    "2. Process speech commands using Vosk\n",
    "3. Understand user intents and execute appropriate actions\n",
    "4. Respond with synthesized speech\n",
    "5. Maintain context across conversation turns\n",
    "6. Handle errors gracefully\n",
    "\n",
    "Our voice assistant will support multiple domains of functionality:\n",
    "\n",
    "1. **Information queries**: Time, date, weather, general knowledge\n",
    "2. **Media control**: Play/pause/stop music or videos\n",
    "3. **Task management**: Set timers, reminders, or create to-do items\n",
    "4. **System control**: Adjust volume, brightness, or other system settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439231c",
   "metadata": {},
   "source": [
    "### System Architecture\n",
    "\n",
    "Our voice assistant will use a layered architecture:\n",
    "\n",
    "```\n",
    "┌────────────────────┐\n",
    "│  User Interface    │ ← User speech and system responses\n",
    "├────────────────────┤\n",
    "│  Dialog Manager    │ ← Manages conversation flow\n",
    "├────────────────────┤\n",
    "│  Intent Processor  │ ← Identifies user intentions\n",
    "├────────────────────┤\n",
    "│  Speech Services   │ ← Recognition and synthesis\n",
    "├────────────────────┤\n",
    "│  Action Handlers   │ ← Executes tasks based on intents\n",
    "├────────────────────┤\n",
    "│  Resource Access   │ ← APIs, databases, system resources\n",
    "└────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d752734",
   "metadata": {},
   "source": [
    "### Wake Word Detection\n",
    "\n",
    "Most voice assistants use a wake word (like \"Hey Siri\" or \"Alexa\") to:\n",
    "1. Conserve resources by only processing speech when needed\n",
    "2. Avoid responding to background conversations\n",
    "3. Give users control over when the system is listening\n",
    "\n",
    "We'll integrate a wake word detection system using:\n",
    "\n",
    "1. **Porcupine**: A lightweight wake word detection library\n",
    "2. **Custom activation**: Only process full speech recognition after wake word detection\n",
    "\n",
    "Example code for wake word detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8814d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "import pyaudio\n",
    "import struct\n",
    "\n",
    "def detect_wake_word(wake_word=\"computer\"):\n",
    "    # Initialize Porcupine with the desired wake word\n",
    "    porcupine = pvporcupine.create(keywords=[wake_word])\n",
    "    \n",
    "    # Set up audio input\n",
    "    pa = pyaudio.PyAudio()\n",
    "    audio_stream = pa.open(\n",
    "        rate=porcupine.sample_rate,\n",
    "        channels=1,\n",
    "        format=pyaudio.paInt16,\n",
    "        input=True,\n",
    "        frames_per_buffer=porcupine.frame_length\n",
    "    )\n",
    "    \n",
    "    print(f\"Listening for wake word: '{wake_word}'\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            # Read audio frame\n",
    "            pcm = audio_stream.read(porcupine.frame_length)\n",
    "            pcm_unpacked = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "            \n",
    "            # Process audio frame\n",
    "            result = porcupine.process(pcm_unpacked)\n",
    "            \n",
    "            # Check if wake word detected\n",
    "            if result >= 0:\n",
    "                print(f\"Wake word detected!\")\n",
    "                return True\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        if audio_stream is not None:\n",
    "            audio_stream.close()\n",
    "        if pa is not None:\n",
    "            pa.terminate()\n",
    "        if porcupine is not None:\n",
    "            porcupine.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a79a0",
   "metadata": {},
   "source": [
    "### Speech Synthesis\n",
    "\n",
    "To create a truly interactive experience, our assistant needs to speak back to the user. We'll implement text-to-speech using:\n",
    "\n",
    "1. **pyttsx3**: A cross-platform text-to-speech library\n",
    "2. **Response formatting**: Preparing text responses for natural-sounding speech\n",
    "\n",
    "Example code for speech synthesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "class SpeechSynthesizer:\n",
    "    def __init__(self):\n",
    "        # Initialize the TTS engine\n",
    "        self.engine = pyttsx3.init()\n",
    "        \n",
    "        # Configure voice properties\n",
    "        self.engine.setProperty('rate', 150)  # Speed of speech\n",
    "        self.engine.setProperty('volume', 0.9)  # Volume (0.0 to 1.0)\n",
    "        \n",
    "        # Get available voices\n",
    "        voices = self.engine.getProperty('voices')\n",
    "        \n",
    "        # Set a voice (uncomment to choose a specific voice)\n",
    "        # self.engine.setProperty('voice', voices[1].id)  # Index 1 is often a female voice\n",
    "    \n",
    "    def speak(self, text):\n",
    "        \"\"\"Speak the given text.\"\"\"\n",
    "        print(f\"Assistant: {text}\")\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "    \n",
    "    def change_voice(self, gender=\"female\"):\n",
    "        \"\"\"Change the voice based on gender preference.\"\"\"\n",
    "        voices = self.engine.getProperty('voices')\n",
    "        \n",
    "        for voice in voices:\n",
    "            # This is a simple heuristic - voice naming conventions differ by system\n",
    "            if gender == \"male\" and \"male\" in voice.name.lower():\n",
    "                self.engine.setProperty('voice', voice.id)\n",
    "                return True\n",
    "            elif gender == \"female\" and \"female\" in voice.name.lower():\n",
    "                self.engine.setProperty('voice', voice.id)\n",
    "                return True\n",
    "        \n",
    "        return False  # No matching voice found\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    synthesizer = SpeechSynthesizer()\n",
    "    synthesizer.speak(\"Hello! I'm your voice assistant. How can I help you today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a334e7",
   "metadata": {},
   "source": [
    "### Configuration Management\n",
    "\n",
    "A good voice assistant should be configurable to adapt to user preferences. We'll implement a configuration system using:\n",
    "\n",
    "1. **JSON configuration file**: Store user preferences and system settings\n",
    "2. **Dynamic reloading**: Allow changing configuration without restart\n",
    "3. **Default values**: Provide sensible defaults for all settings\n",
    "\n",
    "Example code for configuration management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import copy\n",
    "\n",
    "class ConfigManager:\n",
    "    def __init__(self, config_file=\"assistant_config.json\"):\n",
    "        self.config_file = config_file\n",
    "        self.default_config = {\n",
    "            \"assistant\": {\n",
    "                \"name\": \"Assistant\",\n",
    "                \"wake_word\": \"computer\",\n",
    "                \"voice\": {\n",
    "                    \"gender\": \"female\",\n",
    "                    \"rate\": 150,\n",
    "                    \"volume\": 0.9\n",
    "                }\n",
    "            },\n",
    "            \"audio\": {\n",
    "                \"input_device\": -1,  # Default device\n",
    "                \"output_device\": -1,  # Default device\n",
    "                \"sample_rate\": 16000,\n",
    "                \"channels\": 1\n",
    "            },\n",
    "            \"speech\": {\n",
    "                \"model_path\": \"path/to/model\",\n",
    "                \"language\": \"en-us\"\n",
    "            },\n",
    "            \"features\": {\n",
    "                \"weather_enabled\": True,\n",
    "                \"timer_enabled\": True,\n",
    "                \"music_enabled\": True,\n",
    "                \"general_knowledge_enabled\": True\n",
    "            },\n",
    "            \"api_keys\": {\n",
    "                \"weather_api_key\": \"\",\n",
    "                \"news_api_key\": \"\"\n",
    "            }\n",
    "        }\n",
    "        self.config = self.load_config()\n",
    "    \n",
    "    def load_config(self):\n",
    "        \"\"\"Load configuration from file or create with defaults if it doesn't exist.\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.config_file):\n",
    "                with open(self.config_file, 'r') as f:\n",
    "                    loaded_config = json.load(f)\n",
    "                \n",
    "                # Merge with defaults to ensure all keys exist\n",
    "                return self.merge_configs(self.default_config, loaded_config)\n",
    "            else:\n",
    "                # Create new config file with defaults\n",
    "                self.save_config(self.default_config)\n",
    "                return copy.deepcopy(self.default_config)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading configuration: {e}\")\n",
    "            return copy.deepcopy(self.default_config)\n",
    "    \n",
    "    def merge_configs(self, default, loaded):\n",
    "        \"\"\"Recursively merge loaded config with default config.\"\"\"\n",
    "        result = copy.deepcopy(default)\n",
    "        \n",
    "        for key, value in loaded.items():\n",
    "            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n",
    "                result[key] = self.merge_configs(result[key], value)\n",
    "            else:\n",
    "                result[key] = value\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def save_config(self, config=None):\n",
    "        \"\"\"Save configuration to file.\"\"\"\n",
    "        if config is None:\n",
    "            config = self.config\n",
    "            \n",
    "        try:\n",
    "            with open(self.config_file, 'w') as f:\n",
    "                json.dump(config, f, indent=4)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving configuration: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get(self, path, default=None):\n",
    "        \"\"\"Get a configuration value by dot-separated path.\"\"\"\n",
    "        parts = path.split('.')\n",
    "        config = self.config\n",
    "        \n",
    "        for part in parts:\n",
    "            if part in config:\n",
    "                config = config[part]\n",
    "            else:\n",
    "                return default\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def set(self, path, value):\n",
    "        \"\"\"Set a configuration value by dot-separated path.\"\"\"\n",
    "        parts = path.split('.')\n",
    "        config = self.config\n",
    "        \n",
    "        # Navigate to the correct nested dictionary\n",
    "        for i, part in enumerate(parts[:-1]):\n",
    "            if part not in config:\n",
    "                config[part] = {}\n",
    "            config = config[part]\n",
    "        \n",
    "        # Set the value\n",
    "        config[parts[-1]] = value\n",
    "        \n",
    "        # Save the updated configuration\n",
    "        return self.save_config()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    config = ConfigManager()\n",
    "    \n",
    "    # Get values\n",
    "    wake_word = config.get(\"assistant.wake_word\", \"assistant\")\n",
    "    print(f\"Wake word: {wake_word}\")\n",
    "    \n",
    "    # Set values\n",
    "    config.set(\"assistant.wake_word\", \"jarvis\")\n",
    "    print(f\"New wake word: {config.get('assistant.wake_word')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72428",
   "metadata": {},
   "source": [
    "### Action Handlers\n",
    "\n",
    "Our voice assistant needs to perform actions based on user intents. We'll implement a plugin-based action system:\n",
    "\n",
    "1. **Domain-specific handlers**: Separate handlers for different domains (weather, time, etc.)\n",
    "2. **Common interface**: All handlers follow the same interface for consistent processing\n",
    "3. **Dynamic registration**: Handlers can be added or removed without changing core code\n",
    "\n",
    "Example code for the action handling framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionHandler:\n",
    "    \"\"\"Base class for all action handlers.\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"Initialize with optional configuration.\"\"\"\n",
    "        self.config = config\n",
    "    \n",
    "    def can_handle(self, intent, entities):\n",
    "        \"\"\"Check if this handler can handle the given intent and entities.\"\"\"\n",
    "        return False\n",
    "    \n",
    "    def handle(self, intent, entities):\n",
    "        \"\"\"Handle the intent and entities, returning a response.\"\"\"\n",
    "        return \"I'm not sure how to handle that.\"\n",
    "    \n",
    "    def get_supported_intents(self):\n",
    "        \"\"\"Return a list of intents this handler can process.\"\"\"\n",
    "        return []\n",
    "\n",
    "\n",
    "class TimeHandler(ActionHandler):\n",
    "    \"\"\"Handler for time-related intents.\"\"\"\n",
    "    \n",
    "    def get_supported_intents(self):\n",
    "        return [\"time_inquiry\", \"date_inquiry\", \"day_inquiry\"]\n",
    "    \n",
    "    def can_handle(self, intent, entities):\n",
    "        return intent in self.get_supported_intents()\n",
    "    \n",
    "    def handle(self, intent, entities):\n",
    "        import time\n",
    "        import datetime\n",
    "        \n",
    "        if intent == \"time_inquiry\":\n",
    "            current_time = time.strftime(\"%I:%M %p\")\n",
    "            return f\"The current time is {current_time}.\"\n",
    "            \n",
    "        elif intent == \"date_inquiry\":\n",
    "            current_date = time.strftime(\"%A, %B %d, %Y\")\n",
    "            return f\"Today is {current_date}.\"\n",
    "            \n",
    "        elif intent == \"day_inquiry\":\n",
    "            day_of_week = datetime.datetime.now().strftime(\"%A\")\n",
    "            return f\"Today is {day_of_week}.\"\n",
    "            \n",
    "        return \"I'm not sure about the time information you're asking for.\"\n",
    "\n",
    "\n",
    "class WeatherHandler(ActionHandler):\n",
    "    \"\"\"Handler for weather-related intents.\"\"\"\n",
    "    \n",
    "    def get_supported_intents(self):\n",
    "        return [\"weather_inquiry\", \"temperature_inquiry\", \"forecast_inquiry\"]\n",
    "    \n",
    "    def can_handle(self, intent, entities):\n",
    "        return intent in self.get_supported_intents()\n",
    "    \n",
    "    def handle(self, intent, entities):\n",
    "        # In a real implementation, this would call a weather API\n",
    "        # For now, we'll return mock data\n",
    "        import random\n",
    "        \n",
    "        conditions = [\"sunny\", \"partly cloudy\", \"cloudy\", \"rainy\", \"stormy\", \"windy\", \"foggy\"]\n",
    "        temperatures = list(range(65, 85))\n",
    "        \n",
    "        location = entities.get(\"location\", \"current location\")\n",
    "        time_frame = entities.get(\"time\", \"today\")\n",
    "        \n",
    "        if intent == \"weather_inquiry\":\n",
    "            condition = random.choice(conditions)\n",
    "            temp = random.choice(temperatures)\n",
    "            return f\"The weather in {location} {time_frame} is {condition} with a temperature of {temp}°F.\"\n",
    "            \n",
    "        elif intent == \"temperature_inquiry\":\n",
    "            temp = random.choice(temperatures)\n",
    "            return f\"The temperature in {location} {time_frame} is {temp}°F.\"\n",
    "            \n",
    "        elif intent == \"forecast_inquiry\":\n",
    "            forecast = [random.choice(conditions) for _ in range(3)]\n",
    "            return f\"The forecast for {location} shows {forecast[0]} today, {forecast[1]} tomorrow, and {forecast[2]} the day after.\"\n",
    "            \n",
    "        return \"I couldn't get the weather information you requested.\"\n",
    "\n",
    "\n",
    "class ActionManager:\n",
    "    \"\"\"Manages all action handlers and routes intents to the appropriate handler.\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"Initialize with optional configuration.\"\"\"\n",
    "        self.config = config\n",
    "        self.handlers = []\n",
    "        \n",
    "        # Register default handlers\n",
    "        self.register_handler(TimeHandler(config))\n",
    "        self.register_handler(WeatherHandler(config))\n",
    "    \n",
    "    def register_handler(self, handler):\n",
    "        \"\"\"Register a new action handler.\"\"\"\n",
    "        self.handlers.append(handler)\n",
    "    \n",
    "    def handle_intent(self, intent, entities):\n",
    "        \"\"\"Handle an intent using the appropriate handler.\"\"\"\n",
    "        # Find a handler that can handle this intent\n",
    "        for handler in self.handlers:\n",
    "            if handler.can_handle(intent, entities):\n",
    "                return handler.handle(intent, entities)\n",
    "        \n",
    "        # No handler found\n",
    "        return f\"I'm not sure how to handle the {intent} intent.\"\n",
    "    \n",
    "    def get_all_supported_intents(self):\n",
    "        \"\"\"Get a list of all intents supported by registered handlers.\"\"\"\n",
    "        all_intents = []\n",
    "        for handler in self.handlers:\n",
    "            all_intents.extend(handler.get_supported_intents())\n",
    "        return list(set(all_intents))  # Remove duplicates\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create an action manager\n",
    "    action_manager = ActionManager()\n",
    "    \n",
    "    # Test time intent\n",
    "    response = action_manager.handle_intent(\"time_inquiry\", {})\n",
    "    print(response)\n",
    "    \n",
    "    # Test weather intent\n",
    "    response = action_manager.handle_intent(\"weather_inquiry\", {\"location\": \"New York\", \"time\": \"tomorrow\"})\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe513ab",
   "metadata": {},
   "source": [
    "### Dialog Management\n",
    "\n",
    "To create a more conversational experience, we need a dialog manager that can:\n",
    "\n",
    "1. **Maintain context**: Remember previous intents and entities\n",
    "2. **Handle follow-up questions**: Understand context-dependent queries\n",
    "3. **Manage conversation flow**: Guide the user through multi-turn interactions\n",
    "\n",
    "Example code for dialog management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbd398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogManager:\n",
    "    \"\"\"Manages the flow of conversation between user and assistant.\"\"\"\n",
    "    \n",
    "    def __init__(self, action_manager):\n",
    "        \"\"\"Initialize with an action manager.\"\"\"\n",
    "        self.action_manager = action_manager\n",
    "        \n",
    "        # Context maintains state across conversation turns\n",
    "        self.context = {\n",
    "            \"last_intent\": None,\n",
    "            \"entities\": {},\n",
    "            \"conversation_history\": [],\n",
    "            \"active_dialog\": None,\n",
    "            \"dialog_state\": {}\n",
    "        }\n",
    "        \n",
    "        # Define follow-up patterns for common intents\n",
    "        self.follow_up_patterns = {\n",
    "            \"weather_inquiry\": {\n",
    "                \"location_change\": [\"there\", \"in that city\", \"in that location\"],\n",
    "                \"time_change\": [\"tomorrow\", \"next week\", \"this weekend\", \"later\"]\n",
    "            },\n",
    "            \"timer_set\": {\n",
    "                \"change_duration\": [\"longer\", \"shorter\", \"more time\", \"less time\"],\n",
    "                \"cancel\": [\"cancel\", \"stop\", \"delete\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def process_intent(self, intent, entities, text):\n",
    "        \"\"\"Process an intent and update the dialog context.\"\"\"\n",
    "        # Handle follow-up questions based on context\n",
    "        if intent == \"unknown\" or not entities:\n",
    "            intent, entities = self._handle_potential_follow_up(text, intent, entities)\n",
    "        \n",
    "        # Update context\n",
    "        self.context[\"last_intent\"] = intent\n",
    "        \n",
    "        # Add new entities but keep existing ones for context\n",
    "        self.context[\"entities\"].update(entities)\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.context[\"conversation_history\"].append({\n",
    "            \"intent\": intent,\n",
    "            \"entities\": entities.copy(),\n",
    "            \"text\": text,\n",
    "            \"timestamp\": time.time()\n",
    "        })\n",
    "        \n",
    "        # Limit history size\n",
    "        if len(self.context[\"conversation_history\"]) > 10:\n",
    "            self.context[\"conversation_history\"] = self.context[\"conversation_history\"][-10:]\n",
    "        \n",
    "        # Handle multi-turn dialogs\n",
    "        if self.context[\"active_dialog\"]:\n",
    "            return self._continue_dialog(intent, entities)\n",
    "        \n",
    "        # Send to action manager for handling\n",
    "        response = self.action_manager.handle_intent(intent, entities)\n",
    "        \n",
    "        # Check if we need to start a new dialog\n",
    "        if \"needs_more_info\" in entities and entities[\"needs_more_info\"]:\n",
    "            self._start_dialog(intent, entities)\n",
    "            return response\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _handle_potential_follow_up(self, text, intent, entities):\n",
    "        \"\"\"Handle potential follow-up questions based on context.\"\"\"\n",
    "        last_intent = self.context[\"last_intent\"]\n",
    "        \n",
    "        # Skip if no previous context\n",
    "        if not last_intent:\n",
    "            return intent, entities\n",
    "        \n",
    "        # Check follow-up patterns for the last intent\n",
    "        if last_intent in self.follow_up_patterns:\n",
    "            patterns = self.follow_up_patterns[last_intent]\n",
    "            \n",
    "            for pattern_type, phrases in patterns.items():\n",
    "                # If any phrase is in the text, this is likely a follow-up\n",
    "                if any(phrase in text.lower() for phrase in phrases):\n",
    "                    if pattern_type == \"location_change\" and \"location\" not in entities:\n",
    "                        # Extract new location or use default \"there\"\n",
    "                        entities[\"location\"] = \"that location\"  # In a real system, try to extract it\n",
    "                    \n",
    "                    elif pattern_type == \"time_change\" and \"time\" not in entities:\n",
    "                        # Try to extract time reference\n",
    "                        if \"tomorrow\" in text.lower():\n",
    "                            entities[\"time\"] = \"tomorrow\"\n",
    "                        elif \"weekend\" in text.lower():\n",
    "                            entities[\"time\"] = \"this weekend\"\n",
    "                        elif \"week\" in text.lower():\n",
    "                            entities[\"time\"] = \"next week\"\n",
    "                        else:\n",
    "                            entities[\"time\"] = \"later\"\n",
    "                    \n",
    "                    # Use the previous intent since this is a follow-up\n",
    "                    intent = last_intent\n",
    "                    \n",
    "                    # Add any missing entities from previous context\n",
    "                    for key, value in self.context[\"entities\"].items():\n",
    "                        if key not in entities:\n",
    "                            entities[key] = value\n",
    "                    \n",
    "                    return intent, entities\n",
    "        \n",
    "        return intent, entities\n",
    "    \n",
    "    def _start_dialog(self, intent, entities):\n",
    "        \"\"\"Start a multi-turn dialog for complex intents.\"\"\"\n",
    "        self.context[\"active_dialog\"] = intent\n",
    "        self.context[\"dialog_state\"] = {\n",
    "            \"step\": 0,\n",
    "            \"collected_entities\": entities.copy(),\n",
    "            \"needed_entities\": []  # Would be populated based on the intent\n",
    "        }\n",
    "    \n",
    "    def _continue_dialog(self, intent, entities):\n",
    "        \"\"\"Continue a multi-turn dialog.\"\"\"\n",
    "        dialog = self.context[\"active_dialog\"]\n",
    "        state = self.context[\"dialog_state\"]\n",
    "        \n",
    "        # Update with any new entities\n",
    "        state[\"collected_entities\"].update(entities)\n",
    "        \n",
    "        # This would contain custom logic per dialog type\n",
    "        if dialog == \"complex_booking\":\n",
    "            # Handle a complex booking dialog\n",
    "            pass\n",
    "        \n",
    "        # Check if we have all needed info\n",
    "        if not state[\"needed_entities\"] or all(e in state[\"collected_entities\"] for e in state[\"needed_entities\"]):\n",
    "            # Dialog is complete, process it\n",
    "            result = self.action_manager.handle_intent(dialog, state[\"collected_entities\"])\n",
    "            \n",
    "            # Clear the active dialog\n",
    "            self.context[\"active_dialog\"] = None\n",
    "            self.context[\"dialog_state\"] = {}\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            # Ask for the next piece of information\n",
    "            next_entity = state[\"needed_entities\"][state[\"step\"]]\n",
    "            state[\"step\"] += 1\n",
    "            return f\"I need to know the {next_entity} to complete your request.\"\n",
    "\n",
    "# Example usage with the action manager\n",
    "if __name__ == \"__main__\":\n",
    "    action_manager = ActionManager()\n",
    "    dialog_manager = DialogManager(action_manager)\n",
    "    \n",
    "    # Simulate a conversation\n",
    "    print(dialog_manager.process_intent(\"greeting\", {}, \"Hello there\"))\n",
    "    print(dialog_manager.process_intent(\"weather_inquiry\", {\"location\": \"New York\"}, \"What's the weather in New York?\"))\n",
    "    print(dialog_manager.process_intent(\"unknown\", {}, \"How about tomorrow?\"))\n",
    "    print(dialog_manager.process_intent(\"time_inquiry\", {}, \"What time is it now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7b465",
   "metadata": {},
   "source": [
    "### Putting It All Together\n",
    "\n",
    "Now let's integrate all these components into a complete voice assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a79c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceAssistant:\n",
    "    \"\"\"Complete voice assistant integrating all components.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_file=\"assistant_config.json\"):\n",
    "        \"\"\"Initialize the voice assistant.\"\"\"\n",
    "        # Set up configuration\n",
    "        self.config_manager = ConfigManager(config_file)\n",
    "        \n",
    "        # Create component instances\n",
    "        self.speech_synthesizer = SpeechSynthesizer()\n",
    "        self.action_manager = ActionManager(self.config_manager)\n",
    "        self.dialog_manager = DialogManager(self.action_manager)\n",
    "        \n",
    "        # Configure voice based on settings\n",
    "        voice_gender = self.config_manager.get(\"assistant.voice.gender\", \"female\")\n",
    "        self.speech_synthesizer.change_voice(voice_gender)\n",
    "        \n",
    "        # Voice recognition components\n",
    "        self.is_running = False\n",
    "        self.is_listening = False\n",
    "        self.audio_processor = None\n",
    "        self.recognizer = None\n",
    "        self.understanding = None\n",
    "        \n",
    "        # Thread references\n",
    "        self.threads = []\n",
    "    \n",
    "    def setup_recognition(self):\n",
    "        \"\"\"Set up the speech recognition components.\"\"\"\n",
    "        from threading_components import ThreadedAudioProcessor, ThreadedRecognition, ThreadedUnderstanding\n",
    "        \n",
    "        # Create audio processor\n",
    "        self.audio_processor = ThreadedAudioProcessor()\n",
    "        \n",
    "        # Create recognizer with Vosk\n",
    "        model_path = self.config_manager.get(\"speech.model_path\")\n",
    "        self.recognizer = ThreadedRecognition(self.audio_processor.get_audio_queue(), model_path)\n",
    "        \n",
    "        # Create understanding component\n",
    "        self.understanding = ThreadedUnderstanding(self.recognizer.get_text_queue())\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the voice assistant.\"\"\"\n",
    "        if self.is_running:\n",
    "            print(\"Voice assistant is already running\")\n",
    "            return\n",
    "        \n",
    "        # Set up recognition if not already done\n",
    "        if not self.recognizer:\n",
    "            self.setup_recognition()\n",
    "        \n",
    "        # Start the components\n",
    "        self.is_running = True\n",
    "        self.audio_processor.start_processing()\n",
    "        self.recognizer.start_recognition(self.audio_processor.get_sample_rate())\n",
    "        self.understanding.start_understanding()\n",
    "        \n",
    "        # Start the wake word detection thread\n",
    "        wake_word = self.config_manager.get(\"assistant.wake_word\", \"computer\")\n",
    "        wake_thread = threading.Thread(target=self._wake_word_thread, args=(wake_word,))\n",
    "        wake_thread.daemon = True\n",
    "        wake_thread.start()\n",
    "        self.threads.append(wake_thread)\n",
    "        \n",
    "        # Start the intent processing thread\n",
    "        intent_thread = threading.Thread(target=self._intent_processing_thread)\n",
    "        intent_thread.daemon = True\n",
    "        intent_thread.start()\n",
    "        self.threads.append(intent_thread)\n",
    "        \n",
    "        # Give a welcome message\n",
    "        assistant_name = self.config_manager.get(\"assistant.name\", \"Assistant\")\n",
    "        self.speech_synthesizer.speak(f\"Hello, I'm {assistant_name}. Say the wake word '{wake_word}' to get my attention.\")\n",
    "    \n",
    "    def _wake_word_thread(self, wake_word):\n",
    "        \"\"\"Thread that listens for the wake word.\"\"\"\n",
    "        import pvporcupine\n",
    "        import struct\n",
    "        \n",
    "        try:\n",
    "            # Initialize Porcupine\n",
    "            porcupine = pvporcupine.create(keywords=[wake_word])\n",
    "            \n",
    "            while self.is_running:\n",
    "                # Toggle listening mode\n",
    "                if not self.is_listening:\n",
    "                    try:\n",
    "                        # Set up audio for wake word detection\n",
    "                        pa = pyaudio.PyAudio()\n",
    "                        audio_stream = pa.open(\n",
    "                            rate=porcupine.sample_rate,\n",
    "                            channels=1,\n",
    "                            format=pyaudio.paInt16,\n",
    "                            input=True,\n",
    "                            frames_per_buffer=porcupine.frame_length\n",
    "                        )\n",
    "                        \n",
    "                        print(f\"Listening for wake word: '{wake_word}'\")\n",
    "                        \n",
    "                        while self.is_running and not self.is_listening:\n",
    "                            # Read audio frame\n",
    "                            pcm = audio_stream.read(porcupine.frame_length, exception_on_overflow=False)\n",
    "                            pcm_unpacked = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "                            \n",
    "                            # Process audio frame\n",
    "                            result = porcupine.process(pcm_unpacked)\n",
    "                            \n",
    "                            # Check if wake word detected\n",
    "                            if result >= 0:\n",
    "                                print(\"Wake word detected!\")\n",
    "                                self.is_listening = True\n",
    "                                self.speech_synthesizer.speak(\"Yes, how can I help you?\")\n",
    "                                break\n",
    "                    \n",
    "                    finally:\n",
    "                        # Clean up\n",
    "                        if 'audio_stream' in locals() and audio_stream is not None:\n",
    "                            audio_stream.close()\n",
    "                        if 'pa' in locals() and pa is not None:\n",
    "                            pa.terminate()\n",
    "                \n",
    "                # If we're actively listening, sleep and wait for it to finish\n",
    "                else:\n",
    "                    time.sleep(0.1)\n",
    "        \n",
    "        finally:\n",
    "            # Clean up Porcupine\n",
    "            if 'porcupine' in locals() and porcupine is not None:\n",
    "                porcupine.delete()\n",
    "    \n",
    "    def _intent_processing_thread(self):\n",
    "        \"\"\"Thread that processes intents.\"\"\"\n",
    "        try:\n",
    "            intent_queue = self.understanding.get_intent_queue()\n",
    "            \n",
    "            while self.is_running:\n",
    "                if self.is_listening:\n",
    "                    try:\n",
    "                        # Get intent data with timeout\n",
    "                        intent_data = intent_queue.get(timeout=0.5)\n",
    "                        \n",
    "                        # Extract intent and entities\n",
    "                        intent = intent_data[\"intent\"]\n",
    "                        entities = intent_data[\"entities\"]\n",
    "                        text = intent_data[\"text\"]\n",
    "                        \n",
    "                        # Process through dialog manager\n",
    "                        response = self.dialog_manager.process_intent(intent, entities, text)\n",
    "                        \n",
    "                        # Generate speech response\n",
    "                        self.speech_synthesizer.speak(response)\n",
    "                        \n",
    "                        # Stop active listening after processing\n",
    "                        self.is_listening = False\n",
    "                        \n",
    "                        # Mark as done\n",
    "                        intent_queue.task_done()\n",
    "                        \n",
    "                    except queue.Empty:\n",
    "                        # No intent data available, check if we should time out\n",
    "                        pass\n",
    "                else:\n",
    "                    # Not actively listening, just sleep\n",
    "                    time.sleep(0.1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in intent processing thread: {e}\")\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the voice assistant.\"\"\"\n",
    "        if not self.is_running:\n",
    "            print(\"Voice assistant is not running\")\n",
    "            return\n",
    "        \n",
    "        print(\"Stopping voice assistant...\")\n",
    "        self.is_running = False\n",
    "        self.is_listening = False\n",
    "        \n",
    "        # Stop components\n",
    "        if self.understanding:\n",
    "            self.understanding.stop_understanding()\n",
    "        if self.recognizer:\n",
    "            self.recognizer.stop_recognition()\n",
    "        if self.audio_processor:\n",
    "            self.audio_processor.stop_processing()\n",
    "        \n",
    "        # Wait for threads to finish\n",
    "        for thread in self.threads:\n",
    "            if thread.is_alive():\n",
    "                thread.join(timeout=2.0)\n",
    "        \n",
    "        self.speech_synthesizer.speak(\"Goodbye!\")\n",
    "        print(\"Voice assistant stopped\")\n",
    "\n",
    "\n",
    "# Main function to run the complete assistant\n",
    "def main():\n",
    "    # Create the voice assistant\n",
    "    assistant = VoiceAssistant()\n",
    "    \n",
    "    try:\n",
    "        # Start the assistant\n",
    "        assistant.start()\n",
    "        \n",
    "        print(\"Voice Assistant is running. Press Ctrl+C to exit.\")\n",
    "        \n",
    "        # Keep the main thread alive\n",
    "        while True:\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping voice assistant (keyboard interrupt)...\")\n",
    "    \n",
    "    finally:\n",
    "        # Stop the assistant\n",
    "        assistant.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef9b4f",
   "metadata": {},
   "source": [
    "### Project Extension Ideas\n",
    "\n",
    "Here are some ways to extend your voice assistant project:\n",
    "\n",
    "1. **Knowledge Integration**: Connect to Wikipedia or another knowledge base for answering general questions\n",
    "2. **Smart Home Control**: Add handlers for controlling smart home devices via appropriate APIs\n",
    "3. **Multi-user Support**: Add voice identification to personalize responses for different users\n",
    "4. **Contextual Awareness**: Use sensors or system information to make the assistant aware of time of day, device state, etc.\n",
    "5. **Custom Wake Words**: Allow training custom wake words for personalization\n",
    "6. **Web Search Integration**: Add the ability to search the web for information\n",
    "7. **Translation Services**: Add support for translating between languages\n",
    "8. **Voice Customization**: Allow more fine-grained control of voice characteristics\n",
    "9. **Multi-turn Dialog**: Implement more sophisticated dialog flows for complex tasks\n",
    "10. **Continuous Learning**: Add mechanisms for the assistant to learn from interactions\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "You've now learned how to build a complete voice assistant by integrating:\n",
    "\n",
    "1. **Audio processing** for capturing user speech\n",
    "2. **Wake word detection** for efficient resource usage\n",
    "3. **Speech recognition** with Vosk for converting speech to text\n",
    "4. **Natural language understanding** for extracting intents and entities\n",
    "5. **Dialog management** for handling multi-turn conversations\n",
    "6. **Action handling** for executing user requests\n",
    "7. **Speech synthesis** for providing spoken responses\n",
    "8. **Configuration management** for customizing behavior\n",
    "\n",
    "With these components working together, you have a solid foundation for creating more advanced voice assistant applications tailored to your specific needs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
