{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01905137",
   "metadata": {},
   "source": [
    "# SPEECH-TO-TEXT PRACTICE GUIDE\n",
    "\n",
    "## EXERCISE GOAL\n",
    "In this practice session, you'll build a real-time speech recognition system using Vosk and PyAudio. Your program will continuously listen for speech, convert it to text, and detect simple voice commands. This forms the foundation for a voice assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f393b250",
   "metadata": {},
   "source": [
    "## STEP-BY-STEP INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee3d94",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Your Project\n",
    "Let's start by importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6944dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import queue\n",
    "import threading\n",
    "from scipy.signal import butter, lfilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress excessive Vosk logging\n",
    "SetLogLevel(-1)\n",
    "\n",
    "# Check that all imports were successful\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c083cd",
   "metadata": {},
   "source": [
    "### Step 2: Define Helper Functions for Audio Processing\n",
    "\n",
    "First, let's create some helper functions for audio processing and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(audio, sr, lowcut=300, highcut=3000, order=5):\n",
    "    \"\"\"Apply a bandpass filter to focus on speech frequencies\"\"\"\n",
    "    nyquist = 0.5 * sr\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return lfilter(b, a, audio)\n",
    "\n",
    "def normalize_audio(audio, target_dB=-3):\n",
    "    \"\"\"Normalize audio to a target decibel level\"\"\"\n",
    "    # Find the maximum absolute amplitude\n",
    "    max_amplitude = np.max(np.abs(audio))\n",
    "    \n",
    "    # Calculate current peak in dB\n",
    "    current_dB = 20 * np.log10(max_amplitude) if max_amplitude > 0 else -80\n",
    "    \n",
    "    # Calculate the gain needed\n",
    "    gain_dB = target_dB - current_dB\n",
    "    gain_linear = 10 ** (gain_dB / 20)\n",
    "    \n",
    "    # Apply gain\n",
    "    normalized = audio * gain_linear\n",
    "    \n",
    "    # Ensure no clipping\n",
    "    if np.max(np.abs(normalized)) > 1.0:\n",
    "        normalized = normalized / np.max(np.abs(normalized))\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def plot_waveform(audio, sr, title=\"Audio Waveform\"):\n",
    "    \"\"\"Plot audio waveform\"\"\"\n",
    "    time_axis = np.linspace(0, len(audio)/sr, len(audio))\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(time_axis, audio)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Test the functions with a simple sine wave\n",
    "sample_rate = 16000\n",
    "duration = 1  # 1 second\n",
    "t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "# Create a test signal with frequencies at 200Hz, 1000Hz and 4000Hz\n",
    "test_signal = 0.3 * np.sin(2 * np.pi * 200 * t) + 0.4 * np.sin(2 * np.pi * 1000 * t) + 0.3 * np.sin(2 * np.pi * 4000 * t)\n",
    "\n",
    "# Apply filtering and normalization\n",
    "filtered_signal = bandpass_filter(test_signal, sample_rate)\n",
    "normalized_signal = normalize_audio(filtered_signal)\n",
    "\n",
    "# Plot the original and processed signals\n",
    "plot_waveform(test_signal, sample_rate, \"Original Test Signal\")\n",
    "plot_waveform(filtered_signal, sample_rate, \"Bandpass Filtered Signal (300-3000Hz)\")\n",
    "plot_waveform(normalized_signal, sample_rate, \"Normalized Signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e327c",
   "metadata": {},
   "source": [
    "### Step 3: Implement Basic Real-time Speech Recognition\n",
    "\n",
    "Now let's implement a basic real-time speech recognition system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRecognizer:\n",
    "    \"\"\"Basic real-time speech recognition with Vosk\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, sample_rate=16000):\n",
    "        \"\"\"\n",
    "        Initialize the recognizer\n",
    "        \n",
    "        Parameters:\n",
    "        - model_path: Path to Vosk model directory\n",
    "        - sample_rate: Audio sample rate (must match what the model expects)\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = 1024\n",
    "        \n",
    "        # Check if model exists\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
    "        \n",
    "        # Load Vosk model\n",
    "        self.model = Model(model_path)\n",
    "        self.recognizer = KaldiRecognizer(self.model, self.sample_rate)\n",
    "        \n",
    "        # PyAudio setup\n",
    "        self.p = None\n",
    "        self.stream = None\n",
    "    \n",
    "    def start_listening(self, max_seconds=10):\n",
    "        \"\"\"\n",
    "        Start listening and recognizing speech\n",
    "        \n",
    "        Parameters:\n",
    "        - max_seconds: Maximum seconds to listen before stopping\n",
    "        \"\"\"\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size\n",
    "        )\n",
    "        \n",
    "        print(f\"Listening for up to {max_seconds} seconds...\")\n",
    "        self.stream.start_stream()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < max_seconds:\n",
    "            try:\n",
    "                # Read audio chunk\n",
    "                data = self.stream.read(self.chunk_size, exception_on_overflow=False)\n",
    "                \n",
    "                # Process with Vosk\n",
    "                if self.recognizer.AcceptWaveform(data):\n",
    "                    result = json.loads(self.recognizer.Result())\n",
    "                    text = result.get(\"text\", \"\")\n",
    "                    if text:\n",
    "                        print(f\"\\nRecognized: {text}\")\n",
    "                else:\n",
    "                    # Show partial results\n",
    "                    partial = json.loads(self.recognizer.PartialResult())\n",
    "                    partial_text = partial.get(\"partial\", \"\")\n",
    "                    if partial_text:\n",
    "                        print(f\"\\rPartial: {partial_text}\", end=\"\", flush=True)\n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "        \n",
    "        # Get final result\n",
    "        final_result = json.loads(self.recognizer.FinalResult())\n",
    "        final_text = final_result.get(\"text\", \"\")\n",
    "        if final_text:\n",
    "            print(f\"\\nFinal: {final_text}\")\n",
    "        \n",
    "        # Clean up\n",
    "        self.stop_listening()\n",
    "        return final_text\n",
    "    \n",
    "    def stop_listening(self):\n",
    "        \"\"\"Stop listening and clean up resources\"\"\"\n",
    "        if self.stream:\n",
    "            self.stream.stop_stream()\n",
    "            self.stream.close()\n",
    "            self.stream = None\n",
    "        \n",
    "        if self.p:\n",
    "            self.p.terminate()\n",
    "            self.p = None\n",
    "            \n",
    "        print(\"Stopped listening\")\n",
    "\n",
    "# Define path to your Vosk model\n",
    "model_path = \"models/vosk-model-small-en-us-0.15\"\n",
    "\n",
    "# Check if the model exists, provide guidance if it doesn't\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Model not found at {model_path}\")\n",
    "    print(\"Please download a model from https://alphacephei.com/vosk/models\")\n",
    "    print(\"For example, download vosk-model-small-en-us-0.15.zip and extract it to the models directory\")\n",
    "else:\n",
    "    print(f\"Found model at {model_path}\")\n",
    "    \n",
    "    # Uncomment to test the basic recognizer\n",
    "    # recognizer = BasicRecognizer(model_path)\n",
    "    # recognizer.start_listening(max_seconds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790e1c4",
   "metadata": {},
   "source": [
    "### Step 4: Enhance the Recognizer with Preprocessing\n",
    "\n",
    "Now let's add preprocessing to improve recognition accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedRecognizer(BasicRecognizer):\n",
    "    \"\"\"Enhanced speech recognizer with preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, sample_rate=16000):\n",
    "        super().__init__(model_path, sample_rate)\n",
    "        \n",
    "        # Preprocessing settings\n",
    "        self.enable_bandpass = True\n",
    "        self.enable_normalization = True\n",
    "        self.bandpass_lowcut = 300\n",
    "        self.bandpass_highcut = 3000\n",
    "        \n",
    "        # For silence detection\n",
    "        self.silence_threshold = 700  # Adjust based on your microphone\n",
    "        self.speech_detected = False\n",
    "        self.last_speech_time = 0\n",
    "        self.silence_timeout = 2.0  # Seconds of silence to end recognition\n",
    "    \n",
    "    def preprocess_audio(self, audio_bytes):\n",
    "        \"\"\"\n",
    "        Preprocess audio data\n",
    "        \n",
    "        Parameters:\n",
    "        - audio_bytes: Raw audio bytes from PyAudio\n",
    "        \n",
    "        Returns:\n",
    "        - processed_bytes: Processed audio bytes\n",
    "        - is_speech: Whether speech was detected\n",
    "        \"\"\"\n",
    "        # Convert bytes to numpy array\n",
    "        audio = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32767.0\n",
    "        \n",
    "        # Check audio level for silence detection\n",
    "        audio_level = np.max(np.abs(audio)) * 32767\n",
    "        is_speech = audio_level > self.silence_threshold\n",
    "        \n",
    "        # Apply preprocessing if enabled\n",
    "        if self.enable_normalization:\n",
    "            audio = normalize_audio(audio)\n",
    "        \n",
    "        if self.enable_bandpass:\n",
    "            audio = bandpass_filter(audio, self.sample_rate, \n",
    "                                    self.bandpass_lowcut, self.bandpass_highcut)\n",
    "        \n",
    "        # Convert back to bytes\n",
    "        processed_bytes = (audio * 32767).astype(np.int16).tobytes()\n",
    "        \n",
    "        return processed_bytes, is_speech\n",
    "    \n",
    "    def start_listening(self, max_seconds=30):\n",
    "        \"\"\"\n",
    "        Start listening with enhanced processing\n",
    "        \n",
    "        Parameters:\n",
    "        - max_seconds: Maximum seconds to listen before stopping\n",
    "        \"\"\"\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size\n",
    "        )\n",
    "        \n",
    "        print(f\"Listening for up to {max_seconds} seconds...\")\n",
    "        print(\"Speak clearly, pausing for 2 seconds will stop recognition\")\n",
    "        self.stream.start_stream()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.speech_detected = False\n",
    "        self.last_speech_time = start_time\n",
    "        \n",
    "        try:\n",
    "            while time.time() - start_time < max_seconds:\n",
    "                # Read audio chunk\n",
    "                data = self.stream.read(self.chunk_size, exception_on_overflow=False)\n",
    "                \n",
    "                # Preprocess audio\n",
    "                processed_data, is_speech = self.preprocess_audio(data)\n",
    "                \n",
    "                # Update speech detection state\n",
    "                if is_speech:\n",
    "                    if not self.speech_detected:\n",
    "                        print(\"\\nSpeech detected...\")\n",
    "                    self.speech_detected = True\n",
    "                    self.last_speech_time = time.time()\n",
    "                elif self.speech_detected and time.time() - self.last_speech_time > self.silence_timeout:\n",
    "                    print(\"\\nSilence detected, finalizing...\")\n",
    "                    break\n",
    "                \n",
    "                # Process with Vosk\n",
    "                if self.recognizer.AcceptWaveform(processed_data):\n",
    "                    result = json.loads(self.recognizer.Result())\n",
    "                    text = result.get(\"text\", \"\")\n",
    "                    if text:\n",
    "                        print(f\"\\nRecognized: {text}\")\n",
    "                else:\n",
    "                    # Show partial results\n",
    "                    partial = json.loads(self.recognizer.PartialResult())\n",
    "                    partial_text = partial.get(\"partial\", \"\")\n",
    "                    if partial_text:\n",
    "                        print(f\"\\rPartial: {partial_text}\", end=\"\", flush=True)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopped by user\")\n",
    "        finally:\n",
    "            # Get final result\n",
    "            final_result = json.loads(self.recognizer.FinalResult())\n",
    "            final_text = final_result.get(\"text\", \"\")\n",
    "            if final_text:\n",
    "                print(f\"\\nFinal result: {final_text}\")\n",
    "            \n",
    "            # Clean up\n",
    "            self.stop_listening()\n",
    "            return final_text\n",
    "\n",
    "# Uncomment to test the enhanced recognizer\n",
    "# if os.path.exists(model_path):\n",
    "#     enhanced_recognizer = EnhancedRecognizer(model_path)\n",
    "#     enhanced_recognizer.start_listening(max_seconds=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54910b2e",
   "metadata": {},
   "source": [
    "### Step 5: Implement Non-Blocking Recognition\n",
    "\n",
    "Now, let's implement a non-blocking version of our recognizer using threading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonBlockingRecognizer:\n",
    "    \"\"\"Non-blocking speech recognizer using threading\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, sample_rate=16000):\n",
    "        \"\"\"Initialize the recognizer\"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.chunk_size = 1024\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        # Check if model exists\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
    "        \n",
    "        # For audio processing\n",
    "        self.p = None\n",
    "        self.stream = None\n",
    "        self.recognizer = None\n",
    "        \n",
    "        # Threading components\n",
    "        self.running = False\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.result_queue = queue.Queue()\n",
    "        \n",
    "        # Preprocessing settings\n",
    "        self.enable_bandpass = True\n",
    "        self.enable_normalization = True\n",
    "        \n",
    "        # Silence detection\n",
    "        self.silence_threshold = 700\n",
    "        self.speech_detected = False\n",
    "        self.last_speech_time = 0\n",
    "        self.silence_timeout = 2.0\n",
    "    \n",
    "    def _audio_callback(self, in_data, frame_count, time_info, status):\n",
    "        \"\"\"PyAudio callback for streaming audio data\"\"\"\n",
    "        self.audio_queue.put(in_data)\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    \n",
    "    def _preprocess_audio(self, audio_bytes):\n",
    "        \"\"\"Preprocess audio data\"\"\"\n",
    "        # Convert bytes to numpy array\n",
    "        audio = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32767.0\n",
    "        \n",
    "        # Check audio level for silence detection\n",
    "        audio_level = np.max(np.abs(audio)) * 32767\n",
    "        is_speech = audio_level > self.silence_threshold\n",
    "        \n",
    "        # Update speech detection state\n",
    "        if is_speech:\n",
    "            if not self.speech_detected:\n",
    "                self.result_queue.put((\"status\", \"Speech detected\"))\n",
    "            self.speech_detected = True\n",
    "            self.last_speech_time = time.time()\n",
    "        elif self.speech_detected and time.time() - self.last_speech_time > self.silence_timeout:\n",
    "            self.speech_detected = False\n",
    "            self.result_queue.put((\"status\", \"Speech ended\"))\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        if self.enable_normalization:\n",
    "            audio = normalize_audio(audio)\n",
    "        \n",
    "        if self.enable_bandpass:\n",
    "            audio = bandpass_filter(audio, self.sample_rate, 300, 3000)\n",
    "        \n",
    "        # Convert back to bytes\n",
    "        return (audio * 32767).astype(np.int16).tobytes()\n",
    "    \n",
    "    def _process_audio(self):\n",
    "        \"\"\"Process audio data from queue in a separate thread\"\"\"\n",
    "        while self.running:\n",
    "            # Get audio data from queue\n",
    "            if not self.audio_queue.empty():\n",
    "                audio_data = self.audio_queue.get()\n",
    "                \n",
    "                # Preprocess the audio\n",
    "                processed_data = self._preprocess_audio(audio_data)\n",
    "                \n",
    "                # Process with Vosk\n",
    "                if self.recognizer.AcceptWaveform(processed_data):\n",
    "                    result = json.loads(self.recognizer.Result())\n",
    "                    text = result.get(\"text\", \"\")\n",
    "                    if text:\n",
    "                        self.result_queue.put((\"final\", text))\n",
    "                else:\n",
    "                    partial = json.loads(self.recognizer.PartialResult())\n",
    "                    partial_text = partial.get(\"partial\", \"\")\n",
    "                    if partial_text:\n",
    "                        self.result_queue.put((\"partial\", partial_text))\n",
    "            \n",
    "            # Sleep briefly to prevent CPU hogging\n",
    "            time.sleep(0.01)\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the non-blocking recognizer\"\"\"\n",
    "        if self.running:\n",
    "            return\n",
    "        \n",
    "        # Set up Vosk\n",
    "        model = Model(self.model_path)\n",
    "        self.recognizer = KaldiRecognizer(model, self.sample_rate)\n",
    "        \n",
    "        # Set up PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            stream_callback=self._audio_callback\n",
    "        )\n",
    "        \n",
    "        # Reset states\n",
    "        self.running = True\n",
    "        self.speech_detected = False\n",
    "        self.last_speech_time = time.time()\n",
    "        \n",
    "        # Start the processing thread\n",
    "        self.process_thread = threading.Thread(target=self._process_audio)\n",
    "        self.process_thread.daemon = True  # Thread will exit when main program exits\n",
    "        self.process_thread.start()\n",
    "        \n",
    "        # Start the audio stream\n",
    "        self.stream.start_stream()\n",
    "        \n",
    "        print(\"Non-blocking recognizer started\")\n",
    "        return True\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the recognizer\"\"\"\n",
    "        if not self.running:\n",
    "            return\n",
    "        \n",
    "        # Set flag to stop processing thread\n",
    "        self.running = False\n",
    "        \n",
    "        # Clean up PyAudio\n",
    "        if self.stream:\n",
    "            self.stream.stop_stream()\n",
    "            self.stream.close()\n",
    "            self.stream = None\n",
    "        \n",
    "        if self.p:\n",
    "            self.p.terminate()\n",
    "            self.p = None\n",
    "        \n",
    "        # Get final result if any\n",
    "        if self.recognizer:\n",
    "            final_result = json.loads(self.recognizer.FinalResult())\n",
    "            final_text = final_result.get(\"text\", \"\")\n",
    "            if final_text:\n",
    "                self.result_queue.put((\"final\", final_text))\n",
    "        \n",
    "        print(\"Recognizer stopped\")\n",
    "    \n",
    "    def get_result(self, block=False, timeout=None):\n",
    "        \"\"\"\n",
    "        Get recognition result if available\n",
    "        \n",
    "        Returns tuple of (type, text) where type is 'final', 'partial', or 'status'\n",
    "        Returns None if no result available\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.result_queue.get(block=block, timeout=timeout)\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "\n",
    "# Example of using the non-blocking recognizer\n",
    "def demo_non_blocking(run_time=15):\n",
    "    \"\"\"Demo of non-blocking recognition\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    recognizer = NonBlockingRecognizer(model_path)\n",
    "    recognizer.start()\n",
    "    \n",
    "    print(f\"Running for {run_time} seconds. Speak now!\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < run_time:\n",
    "            # Check for recognition results\n",
    "            result = recognizer.get_result(block=False)\n",
    "            if result:\n",
    "                result_type, text = result\n",
    "                if result_type == \"partial\":\n",
    "                    print(f\"\\rPartial: {text}\", end=\"\", flush=True)\n",
    "                elif result_type == \"final\":\n",
    "                    print(f\"\\nFinal: {text}\")\n",
    "                elif result_type == \"status\":\n",
    "                    print(f\"\\n{text}\")\n",
    "            \n",
    "            # The main thread could do other things here\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopped by user\")\n",
    "    finally:\n",
    "        recognizer.stop()\n",
    "\n",
    "# Uncomment to run the non-blocking demo\n",
    "# demo_non_blocking(run_time=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a61439",
   "metadata": {},
   "source": [
    "### Step 6: Implement Command Recognition\n",
    "\n",
    "Now, let's implement a simple command recognition system using our speech recognizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommandRecognizer:\n",
    "    \"\"\"Recognizer for specific voice commands\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, commands=None):\n",
    "        \"\"\"\n",
    "        Initialize the command recognizer\n",
    "        \n",
    "        Parameters:\n",
    "        - model_path: Path to Vosk model\n",
    "        - commands: Dictionary of commands and their handlers\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.commands = commands or {}\n",
    "        self.recognizer = NonBlockingRecognizer(model_path)\n",
    "        self.running = False\n",
    "    \n",
    "    def add_command(self, phrase, handler):\n",
    "        \"\"\"\n",
    "        Add a command to recognize\n",
    "        \n",
    "        Parameters:\n",
    "        - phrase: Command phrase to recognize\n",
    "        - handler: Function to call when command is recognized\n",
    "        \"\"\"\n",
    "        self.commands[phrase.lower()] = handler\n",
    "        print(f\"Added command: '{phrase}'\")\n",
    "    \n",
    "    def _command_matches(self, text):\n",
    "        \"\"\"Check if text matches any command\"\"\"\n",
    "        text = text.lower()\n",
    "        \n",
    "        for command, handler in self.commands.items():\n",
    "            # Check for exact match\n",
    "            if command == text:\n",
    "                return handler\n",
    "            \n",
    "            # Check for command contained in text\n",
    "            if command in text:\n",
    "                return handler\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def start_listening(self, max_seconds=60):\n",
    "        \"\"\"\n",
    "        Start listening for commands\n",
    "        \n",
    "        Parameters:\n",
    "        - max_seconds: Maximum seconds to listen\n",
    "        \"\"\"\n",
    "        if not self.commands:\n",
    "            print(\"Warning: No commands added. Use add_command() first.\")\n",
    "        \n",
    "        self.running = True\n",
    "        self.recognizer.start()\n",
    "        \n",
    "        print(f\"Listening for commands for up to {max_seconds} seconds...\")\n",
    "        print(\"Available commands:\")\n",
    "        for command in self.commands.keys():\n",
    "            print(f\"  - {command}\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            while self.running and time.time() - start_time < max_seconds:\n",
    "                # Get recognition results\n",
    "                result = self.recognizer.get_result(block=False)\n",
    "                if result:\n",
    "                    result_type, text = result\n",
    "                    \n",
    "                    if result_type == \"partial\":\n",
    "                        print(f\"\\rListening: {text}\", end=\"\", flush=True)\n",
    "                    \n",
    "                    elif result_type == \"final\":\n",
    "                        print(f\"\\nYou said: {text}\")\n",
    "                        \n",
    "                        # Check for command match\n",
    "                        handler = self._command_matches(text)\n",
    "                        if handler:\n",
    "                            print(f\"Command recognized!\")\n",
    "                            handler(text)\n",
    "                        else:\n",
    "                            print(\"No command matched\")\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopped by user\")\n",
    "        finally:\n",
    "            self.stop_listening()\n",
    "    \n",
    "    def stop_listening(self):\n",
    "        \"\"\"Stop listening for commands\"\"\"\n",
    "        self.running = False\n",
    "        self.recognizer.stop()\n",
    "        print(\"Command recognition stopped\")\n",
    "\n",
    "# Example command handlers\n",
    "def handle_hello(text):\n",
    "    print(\"Hello to you too!\")\n",
    "\n",
    "def handle_time(text):\n",
    "    current_time = time.strftime(\"%H:%M:%S\")\n",
    "    print(f\"The current time is {current_time}\")\n",
    "\n",
    "def handle_weather(text):\n",
    "    print(\"I don't have a weather API connected yet, but it's probably nice outside!\")\n",
    "\n",
    "def handle_lights(text):\n",
    "    if \"on\" in text.lower():\n",
    "        print(\"Turning lights on...\")\n",
    "    elif \"off\" in text.lower():\n",
    "        print(\"Turning lights off...\")\n",
    "    else:\n",
    "        print(\"Do you want the lights on or off?\")\n",
    "\n",
    "# Demonstrate command recognition\n",
    "def demo_command_recognition(run_time=60):\n",
    "    \"\"\"Demo of command recognition\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    # Create command recognizer\n",
    "    cmd_recognizer = CommandRecognizer(model_path)\n",
    "    \n",
    "    # Add commands\n",
    "    cmd_recognizer.add_command(\"hello\", handle_hello)\n",
    "    cmd_recognizer.add_command(\"what time is it\", handle_time)\n",
    "    cmd_recognizer.add_command(\"what's the weather\", handle_weather)\n",
    "    cmd_recognizer.add_command(\"turn on the lights\", handle_lights)\n",
    "    cmd_recognizer.add_command(\"turn off the lights\", handle_lights)\n",
    "    \n",
    "    # Start listening\n",
    "    cmd_recognizer.start_listening(max_seconds=run_time)\n",
    "\n",
    "# Uncomment to run the command recognition demo\n",
    "# demo_command_recognition(run_time=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633f238",
   "metadata": {},
   "source": [
    "### Step 7: Creating a Grammar-Based Recognizer\n",
    "\n",
    "For better accuracy with a limited set of commands, let's implement a grammar-based recognizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5cd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarRecognizer:\n",
    "    \"\"\"Recognizer constrained by grammar for better accuracy\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, grammar_phrases=None):\n",
    "        \"\"\"\n",
    "        Initialize grammar-based recognizer\n",
    "        \n",
    "        Parameters:\n",
    "        - model_path: Path to Vosk model\n",
    "        - grammar_phrases: List of phrases to recognize\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.grammar_phrases = grammar_phrases or []\n",
    "        \n",
    "        # Initialize components\n",
    "        self.p = None\n",
    "        self.stream = None\n",
    "        self.recognizer = None\n",
    "        \n",
    "        # Recognition settings\n",
    "        self.sample_rate = 16000\n",
    "        self.chunk_size = 1024\n",
    "    \n",
    "    def add_phrase(self, phrase):\n",
    "        \"\"\"Add phrase to grammar\"\"\"\n",
    "        self.grammar_phrases.append(phrase.lower())\n",
    "    \n",
    "    def start_listening(self, max_seconds=30):\n",
    "        \"\"\"Start listening with grammar constraint\"\"\"\n",
    "        if not self.grammar_phrases:\n",
    "            print(\"Warning: No phrases added to grammar.\")\n",
    "            return \"\"\n",
    "        \n",
    "        # Create model\n",
    "        model = Model(self.model_path)\n",
    "        \n",
    "        # Create grammar JSON\n",
    "        grammar = {\"grammar\": self.grammar_phrases}\n",
    "        \n",
    "        # Create recognizer with grammar\n",
    "        self.recognizer = KaldiRecognizer(\n",
    "            model, \n",
    "            self.sample_rate, \n",
    "            json.dumps(grammar)\n",
    "        )\n",
    "        \n",
    "        # Initialize PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=self.sample_rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size\n",
    "        )\n",
    "        \n",
    "        print(\"Listening with grammar constraint...\")\n",
    "        print(\"Recognized phrases will be limited to:\")\n",
    "        for phrase in self.grammar_phrases:\n",
    "            print(f\"  - {phrase}\")\n",
    "        \n",
    "        # Start listening\n",
    "        recognized_text = \"\"\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            while time.time() - start_time < max_seconds:\n",
    "                data = self.stream.read(self.chunk_size, exception_on_overflow=False)\n",
    "                \n",
    "                if self.recognizer.AcceptWaveform(data):\n",
    "                    result = json.loads(self.recognizer.Result())\n",
    "                    text = result.get(\"text\", \"\")\n",
    "                    if text:\n",
    "                        print(f\"\\nRecognized: {text}\")\n",
    "                        recognized_text = text\n",
    "                        break  # Stop after first recognition\n",
    "                else:\n",
    "                    partial = json.loads(self.recognizer.PartialResult())\n",
    "                    partial_text = partial.get(\"partial\", \"\")\n",
    "                    if partial_text:\n",
    "                        print(f\"\\rPartial: {partial_text}\", end=\"\", flush=True)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopped by user\")\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if self.stream:\n",
    "                self.stream.stop_stream()\n",
    "                self.stream.close()\n",
    "            \n",
    "            if self.p:\n",
    "                self.p.terminate()\n",
    "            \n",
    "            print(\"\\nGrammar-based recognition completed\")\n",
    "        \n",
    "        return recognized_text\n",
    "\n",
    "# Demo of grammar-based recognition\n",
    "def demo_grammar_recognition():\n",
    "    \"\"\"Demo grammar-based recognition\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    # Create grammar recognizer\n",
    "    grammar_rec = GrammarRecognizer(model_path)\n",
    "    \n",
    "    # Add phrases\n",
    "    grammar_rec.add_phrase(\"turn on the lights\")\n",
    "    grammar_rec.add_phrase(\"turn off the lights\")\n",
    "    grammar_rec.add_phrase(\"what time is it\")\n",
    "    grammar_rec.add_phrase(\"what's the weather\")\n",
    "    grammar_rec.add_phrase(\"play music\")\n",
    "    grammar_rec.add_phrase(\"stop music\")\n",
    "    grammar_rec.add_phrase(\"open the door\")\n",
    "    grammar_rec.add_phrase(\"close the door\")\n",
    "    \n",
    "    # Start listening\n",
    "    recognized = grammar_rec.start_listening(max_seconds=15)\n",
    "    \n",
    "    if recognized:\n",
    "        print(f\"\\nFinal recognized command: '{recognized}'\")\n",
    "        print(\"Taking action based on command...\")\n",
    "        \n",
    "        # Simple command handling\n",
    "        if \"light\" in recognized:\n",
    "            if \"on\" in recognized:\n",
    "                print(\"Turning lights on!\")\n",
    "            else:\n",
    "                print(\"Turning lights off!\")\n",
    "        elif \"time\" in recognized:\n",
    "            current_time = time.strftime(\"%H:%M:%S\")\n",
    "            print(f\"The current time is {current_time}\")\n",
    "        elif \"music\" in recognized:\n",
    "            if \"play\" in recognized:\n",
    "                print(\"Playing your favorite music...\")\n",
    "            else:\n",
    "                print(\"Stopping music playback.\")\n",
    "        elif \"door\" in recognized:\n",
    "            if \"open\" in recognized:\n",
    "                print(\"Opening the door...\")\n",
    "            else:\n",
    "                print(\"Closing the door...\")\n",
    "        elif \"weather\" in recognized:\n",
    "            print(\"The weather is sunny with a chance of Python!\")\n",
    "\n",
    "# Uncomment to run the grammar-based recognition demo\n",
    "# demo_grammar_recognition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff1884",
   "metadata": {},
   "source": [
    "### Step 8: Put Everything Together - A Simple Voice Assistant\n",
    "\n",
    "Now, let's bring everything together to create a simple voice assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVoiceAssistant:\n",
    "    \"\"\"A simple voice assistant using our speech recognition components\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, wake_word=\"hey assistant\"):\n",
    "        \"\"\"\n",
    "        Initialize voice assistant\n",
    "        \n",
    "        Parameters:\n",
    "        - model_path: Path to Vosk model\n",
    "        - wake_word: Wake word to activate assistant\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.wake_word = wake_word.lower()\n",
    "        \n",
    "        # Recognition components\n",
    "        self.listener = NonBlockingRecognizer(model_path)\n",
    "        self.command_recognizer = GrammarRecognizer(model_path)\n",
    "        \n",
    "        # Assistant state\n",
    "        self.running = False\n",
    "        self.listening_for_wake_word = True\n",
    "        self.listening_for_command = False\n",
    "        \n",
    "        # Set up command grammar\n",
    "        self._setup_commands()\n",
    "    \n",
    "    def _setup_commands(self):\n",
    "        \"\"\"Set up the available commands\"\"\"\n",
    "        commands = [\n",
    "            \"what time is it\",\n",
    "            \"what's the weather\",\n",
    "            \"tell me a joke\",\n",
    "            \"turn on the lights\",\n",
    "            \"turn off the lights\",\n",
    "            \"play music\",\n",
    "            \"stop music\",\n",
    "            \"goodbye\"\n",
    "        ]\n",
    "        \n",
    "        for command in commands:\n",
    "            self.command_recognizer.add_phrase(command)\n",
    "    \n",
    "    def _handle_command(self, command):\n",
    "        \"\"\"Handle recognized command\"\"\"\n",
    "        if not command:\n",
    "            print(\"Sorry, I didn't understand that command.\")\n",
    "            return True\n",
    "        \n",
    "        command = command.lower()\n",
    "        \n",
    "        if \"time\" in command:\n",
    "            current_time = time.strftime(\"%I:%M %p\")\n",
    "            print(f\"It's {current_time}\")\n",
    "        \n",
    "        elif \"weather\" in command:\n",
    "            print(\"I don't have a weather API connected yet, but I'm sure it's lovely outside!\")\n",
    "        \n",
    "        elif \"joke\" in command:\n",
    "            jokes = [\n",
    "                \"Why do programmers prefer dark mode? Because light attracts bugs!\",\n",
    "                \"Why did the function go to therapy? It had too many complex issues.\",\n",
    "                \"What's a computer's favorite snack? Microchips!\",\n",
    "                \"Why did the programmer quit his job? Because he didn't get arrays.\"\n",
    "            ]\n",
    "            print(f\"Here's a joke: {np.random.choice(jokes)}\")\n",
    "        \n",
    "        elif \"light\" in command:\n",
    "            if \"on\" in command:\n",
    "                print(\"Turning the lights on!\")\n",
    "            else:\n",
    "                print(\"Turning the lights off!\")\n",
    "        \n",
    "        elif \"music\" in command:\n",
    "            if \"play\" in command:\n",
    "                print(\"Playing your favorite music...\")\n",
    "            else:\n",
    "                print(\"Stopping music playback.\")\n",
    "        \n",
    "        elif \"goodbye\" in command:\n",
    "            print(\"Goodbye! Have a great day!\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def run(self, run_time=120):\n",
    "        \"\"\"\n",
    "        Run the voice assistant\n",
    "        \n",
    "        Parameters:\n",
    "        - run_time: Maximum run time in seconds\n",
    "        \"\"\"\n",
    "        self.running = True\n",
    "        self.listener.start()\n",
    "        \n",
    "        print(f\"Voice assistant started! Say '{self.wake_word}' to activate.\")\n",
    "        print(f\"Running for up to {run_time} seconds (Ctrl+C to exit)\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            while self.running and time.time() - start_time < run_time:\n",
    "                if self.listening_for_wake_word:\n",
    "                    # Listen for wake word\n",
    "                    result = self.listener.get_result(block=False)\n",
    "                    if result:\n",
    "                        result_type, text = result\n",
    "                        if result_type == \"final\":\n",
    "                            print(f\"\\nHeard: {text}\")\n",
    "                            \n",
    "                            # Check for wake word\n",
    "                            if self.wake_word in text.lower():\n",
    "                                print(f\"Wake word detected! What can I help you with?\")\n",
    "                                \n",
    "                                # Stop wake word listener and switch to command mode\n",
    "                                self.listener.stop()\n",
    "                                self.listening_for_wake_word = False\n",
    "                                self.listening_for_command = True\n",
    "                                \n",
    "                                # Get command\n",
    "                                command = self.command_recognizer.start_listening(max_seconds=10)\n",
    "                                \n",
    "                                # Handle command\n",
    "                                if self._handle_command(command):\n",
    "                                    # Restart wake word listener\n",
    "                                    self.listening_for_wake_word = True\n",
    "                                    self.listening_for_command = False\n",
    "                                    self.listener.start()\n",
    "                                else:\n",
    "                                    # Command was \"goodbye\"\n",
    "                                    self.running = False\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nVoice assistant stopped by user\")\n",
    "        finally:\n",
    "            if self.listener.running:\n",
    "                self.listener.stop()\n",
    "            print(\"Voice assistant shutdown complete\")\n",
    "\n",
    "# Demo the simple voice assistant\n",
    "def start_voice_assistant():\n",
    "    \"\"\"Start the simple voice assistant\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}\")\n",
    "        return\n",
    "    \n",
    "    assistant = SimpleVoiceAssistant(model_path, wake_word=\"hey assistant\")\n",
    "    assistant.run(run_time=120)\n",
    "\n",
    "# Uncomment to start the voice assistant\n",
    "# start_voice_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a57700",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've built a complete real-time speech recognition system for your voice assistant. In this practice, you've learned how to:\n",
    "\n",
    "1. Capture and process audio in real-time\n",
    "2. Apply preprocessing techniques to improve recognition\n",
    "3. Use threading for non-blocking recognition\n",
    "4. Implement command recognition\n",
    "5. Use grammar constraints for better accuracy\n",
    "6. Create a simple wake-word based voice assistant\n",
    "\n",
    "In the next module, you'll learn about speech understanding - how to extract meaning and intent from the recognized text.\n",
    "\n",
    "## Exploring Further\n",
    "\n",
    "To expand your speech recognition system, you might want to explore:\n",
    "\n",
    "1. Integrating with a more advanced NLU (Natural Language Understanding) system\n",
    "2. Adding more sophisticated voice activity detection\n",
    "3. Implementing adaptive noise cancellation\n",
    "4. Storing and learning from user interactions\n",
    "5. Adding multiple wake word options\n",
    "\n",
    "Feel free to experiment with the code and adapt it to your specific needs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b329551",
   "metadata": {},
   "source": [
    "### Challenge Exercise\n",
    "\n",
    "As a challenge, try to extend the voice assistant to:\n",
    "\n",
    "1. Remember user preferences\n",
    "2. Use environment variables for more natural interactions (e.g., time of day)\n",
    "3. Integrate with a web API (e.g., for weather information)\n",
    "4. Add conversational context (remember previous commands)\n",
    "\n",
    "This will prepare you well for the next modules on Speech Understanding and Integration!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
