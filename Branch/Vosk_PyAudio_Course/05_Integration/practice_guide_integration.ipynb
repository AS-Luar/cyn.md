{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7f68a1",
   "metadata": {},
   "source": [
    "# PRACTICE GUIDE: INTEGRATION OF SPEECH RECOGNITION AND UNDERSTANDING\n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "In this practice session, you will integrate the speech recognition and speech understanding components developed in previous modules to create a cohesive system. This integration will form the foundation for a complete voice assistant.\n",
    "\n",
    "## OBJECTIVES\n",
    "\n",
    "1. Design a modular architecture for the voice assistant\n",
    "2. Implement threaded processing for concurrent operations\n",
    "3. Create a pipeline for audio capture → speech recognition → intent understanding\n",
    "4. Develop a responsive feedback system\n",
    "\n",
    "## PREREQUISITES\n",
    "\n",
    "- Completion of Modules 1-4\n",
    "- Understanding of basic threading concepts in Python\n",
    "- Familiarity with the queue module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbebc50",
   "metadata": {},
   "source": [
    "## PRACTICE EXERCISES\n",
    "\n",
    "### Exercise 1: Design the System Architecture\n",
    "\n",
    "1. Draw a diagram (on paper or using a digital tool) that illustrates:\n",
    "   - Components of the system (audio capture, recognition, understanding)\n",
    "   - Data flow between components\n",
    "   - Threading model\n",
    "   - User feedback mechanisms\n",
    "   \n",
    "2. Document your architecture with comments explaining:\n",
    "   - How components will communicate\n",
    "   - How to manage processing load\n",
    "   - Error handling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a6322",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement a Threaded Audio Processor\n",
    "\n",
    "1. Create a new Python file called `threaded_audio_processor.py`\n",
    "2. Implement a class that:\n",
    "   - Captures audio in a background thread\n",
    "   - Processes audio frames as they become available\n",
    "   - Uses a queue to pass audio data to the recognition component\n",
    "   - Can be started and stopped cleanly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import pyaudio\n",
    "import time\n",
    "\n",
    "class ThreadedAudioProcessor:\n",
    "    def __init__(self, chunk_size=1024, format=pyaudio.paInt16, \n",
    "                 channels=1, rate=16000, buffer_size=10):\n",
    "        \"\"\"Initialize the threaded audio processor.\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: Size of audio chunks to process\n",
    "            format: PyAudio format (default: 16-bit PCM)\n",
    "            channels: Number of audio channels (default: mono)\n",
    "            rate: Sample rate in Hz\n",
    "            buffer_size: Maximum number of frames in queue before blocking\n",
    "        \"\"\"\n",
    "        # Create a queue for audio frames\n",
    "        self.audio_queue = queue.Queue(maxsize=buffer_size)\n",
    "        \n",
    "        # Store audio parameters\n",
    "        self.chunk_size = chunk_size\n",
    "        self.format = format\n",
    "        self.channels = channels\n",
    "        self.rate = rate\n",
    "        \n",
    "        # Thread control flags\n",
    "        self.is_running = False\n",
    "        self.audio_thread = None\n",
    "        \n",
    "        # PyAudio objects\n",
    "        self.p = None\n",
    "        self.stream = None\n",
    "        \n",
    "    def start_processing(self):\n",
    "        \"\"\"Start the audio processing in a background thread.\"\"\"\n",
    "        if self.audio_thread is not None and self.audio_thread.is_alive():\n",
    "            print(\"Audio processing already running!\")\n",
    "            return\n",
    "            \n",
    "        # Create and start the thread\n",
    "        self.is_running = True\n",
    "        self.audio_thread = threading.Thread(target=self.process_audio_thread)\n",
    "        self.audio_thread.daemon = True\n",
    "        self.audio_thread.start()\n",
    "        print(\"Audio processing started.\")\n",
    "        \n",
    "    def process_audio_thread(self):\n",
    "        \"\"\"Process audio in a background thread.\"\"\"\n",
    "        try:\n",
    "            # Initialize PyAudio\n",
    "            self.p = pyaudio.PyAudio()\n",
    "            \n",
    "            # Open audio stream\n",
    "            self.stream = self.p.open(\n",
    "                format=self.format,\n",
    "                channels=self.channels,\n",
    "                rate=self.rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=self.chunk_size\n",
    "            )\n",
    "            \n",
    "            print(f\"Audio stream opened: {self.rate}Hz, {self.channels} channel(s)\")\n",
    "            \n",
    "            # Read frames and add to queue\n",
    "            while self.is_running:\n",
    "                try:\n",
    "                    # Read audio data\n",
    "                    audio_data = self.stream.read(self.chunk_size, exception_on_overflow=False)\n",
    "                    \n",
    "                    # Add to queue, block if queue is full\n",
    "                    self.audio_queue.put(audio_data, block=True, timeout=0.5)\n",
    "                    \n",
    "                except queue.Full:\n",
    "                    print(\"Warning: Audio queue full, dropping frames\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error capturing audio: {str(e)}\")\n",
    "                    # Short sleep to prevent tight loop if error persists\n",
    "                    time.sleep(0.1)\n",
    "            \n",
    "            print(\"Audio capture thread stopping...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in audio thread: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            # Clean up resources\n",
    "            self.cleanup()\n",
    "                \n",
    "    def stop_processing(self):\n",
    "        \"\"\"Stop audio processing and clean up resources.\"\"\"\n",
    "        print(\"Stopping audio processing...\")\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Wait for thread to finish\n",
    "        if self.audio_thread and self.audio_thread.is_alive():\n",
    "            self.audio_thread.join(timeout=2.0)\n",
    "        \n",
    "        self.cleanup()\n",
    "        print(\"Audio processing stopped.\")\n",
    "        \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up audio resources.\"\"\"\n",
    "        if self.stream is not None:\n",
    "            self.stream.stop_stream()\n",
    "            self.stream.close()\n",
    "            self.stream = None\n",
    "            \n",
    "        if self.p is not None:\n",
    "            self.p.terminate()\n",
    "            self.p = None\n",
    "            \n",
    "    def get_audio_queue(self):\n",
    "        \"\"\"Get the queue that contains audio frames.\"\"\"\n",
    "        return self.audio_queue\n",
    "        \n",
    "    def get_sample_rate(self):\n",
    "        \"\"\"Get the audio sample rate.\"\"\"\n",
    "        return self.rate\n",
    "\n",
    "# Test the audio processor\n",
    "if __name__ == \"__main__\":\n",
    "    processor = ThreadedAudioProcessor()\n",
    "    processor.start_processing()\n",
    "    \n",
    "    try:\n",
    "        # Run for 5 seconds as a test\n",
    "        print(\"Recording for 5 seconds...\")\n",
    "        for i in range(5):\n",
    "            time.sleep(1)\n",
    "            print(f\"Queue size: {processor.get_audio_queue().qsize()}\")\n",
    "            \n",
    "    finally:\n",
    "        processor.stop_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5e55d",
   "metadata": {},
   "source": [
    "### Exercise 3: Create a Threaded Recognition System\n",
    "\n",
    "1. Create a Python file called `threaded_recognition.py`\n",
    "2. Implement a class that:\n",
    "   - Takes audio frames from a queue\n",
    "   - Processes them with Vosk in a separate thread\n",
    "   - Outputs recognized text to another queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877395c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import queue\n",
    "import json\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "class ThreadedRecognition:\n",
    "    def __init__(self, audio_queue, model_path, sample_rate=16000):\n",
    "        \"\"\"Initialize the threaded recognition system.\n",
    "        \n",
    "        Args:\n",
    "            audio_queue: Queue containing audio frames to process\n",
    "            model_path: Path to Vosk model\n",
    "            sample_rate: Sample rate of the audio\n",
    "        \"\"\"\n",
    "        # Store the audio queue\n",
    "        self.audio_queue = audio_queue\n",
    "        \n",
    "        # Create a text output queue\n",
    "        self.text_queue = queue.Queue()\n",
    "        \n",
    "        # Store model path and sample rate\n",
    "        self.model_path = model_path\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        # Thread control flags\n",
    "        self.is_running = False\n",
    "        self.recognition_thread = None\n",
    "        \n",
    "        # Vosk objects\n",
    "        self.model = None\n",
    "        self.recognizer = None\n",
    "        \n",
    "        # Recognition state\n",
    "        self.last_partial = \"\"\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize the Vosk model and recognizer.\"\"\"\n",
    "        if not os.path.exists(self.model_path):\n",
    "            raise ValueError(f\"Model path '{self.model_path}' does not exist!\")\n",
    "            \n",
    "        print(f\"Loading Vosk model from {self.model_path}...\")\n",
    "        self.model = Model(self.model_path)\n",
    "        self.recognizer = KaldiRecognizer(self.model, self.sample_rate)\n",
    "        print(\"Vosk model loaded successfully.\")\n",
    "        \n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start the recognition process in a background thread.\"\"\"\n",
    "        if self.recognition_thread is not None and self.recognition_thread.is_alive():\n",
    "            print(\"Recognition already running!\")\n",
    "            return\n",
    "            \n",
    "        # Initialize the model if needed\n",
    "        if self.model is None or self.recognizer is None:\n",
    "            self.initialize_model()\n",
    "            \n",
    "        # Create and start the thread\n",
    "        self.is_running = True\n",
    "        self.recognition_thread = threading.Thread(target=self.recognition_thread_func)\n",
    "        self.recognition_thread.daemon = True\n",
    "        self.recognition_thread.start()\n",
    "        print(\"Speech recognition started.\")\n",
    "        \n",
    "    def recognition_thread_func(self):\n",
    "        \"\"\"The main recognition thread function.\"\"\"\n",
    "        try:\n",
    "            while self.is_running:\n",
    "                try:\n",
    "                    # Get audio data with timeout\n",
    "                    audio_data = self.audio_queue.get(timeout=0.5)\n",
    "                    \n",
    "                    # Process with Vosk\n",
    "                    if self.recognizer.AcceptWaveform(audio_data):\n",
    "                        # We have a final result\n",
    "                        result = json.loads(self.recognizer.Result())\n",
    "                        text = result.get(\"text\", \"\").strip()\n",
    "                        \n",
    "                        if text:  # Only if we actually got some text\n",
    "                            print(f\"Recognized: {text}\")\n",
    "                            # Put the result in the output queue\n",
    "                            self.text_queue.put({\"type\": \"final\", \"text\": text})\n",
    "                            \n",
    "                            # Reset the partial text\n",
    "                            self.last_partial = \"\"\n",
    "                    else:\n",
    "                        # We have a partial result\n",
    "                        result = json.loads(self.recognizer.PartialResult())\n",
    "                        partial = result.get(\"partial\", \"\").strip()\n",
    "                        \n",
    "                        if partial and partial != self.last_partial:\n",
    "                            print(f\"Partial: {partial}\", end=\"\\r\")\n",
    "                            # Update the partial text\n",
    "                            self.last_partial = partial\n",
    "                            # Put the partial result in the queue\n",
    "                            self.text_queue.put({\"type\": \"partial\", \"text\": partial})\n",
    "                    \n",
    "                    # Mark task as done\n",
    "                    self.audio_queue.task_done()\n",
    "                    \n",
    "                except queue.Empty:\n",
    "                    # No audio data available, just continue\n",
    "                    pass\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing audio: {str(e)}\")\n",
    "                    time.sleep(0.1)  # Prevent tight loop if error persists\n",
    "                    \n",
    "            print(\"Recognition thread stopping...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in recognition thread: {str(e)}\")\n",
    "            \n",
    "    def stop_recognition(self):\n",
    "        \"\"\"Stop the recognition process.\"\"\"\n",
    "        print(\"Stopping speech recognition...\")\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Wait for thread to finish\n",
    "        if self.recognition_thread and self.recognition_thread.is_alive():\n",
    "            self.recognition_thread.join(timeout=2.0)\n",
    "            \n",
    "        print(\"Speech recognition stopped.\")\n",
    "        \n",
    "    def get_text_queue(self):\n",
    "        \"\"\"Get the queue that contains recognized text.\"\"\"\n",
    "        return self.text_queue\n",
    "\n",
    "# Test the recognition system\n",
    "if __name__ == \"__main__\":\n",
    "    from threaded_audio_processor import ThreadedAudioProcessor\n",
    "    \n",
    "    # Path to your Vosk model\n",
    "    model_path = \"/home/luar/AI/voice_assistant/vosk-model-small-en-us-0.15\"\n",
    "    \n",
    "    # Create audio processor\n",
    "    audio_processor = ThreadedAudioProcessor()\n",
    "    audio_queue = audio_processor.get_audio_queue()\n",
    "    \n",
    "    # Create recognition system\n",
    "    recognizer = ThreadedRecognition(audio_queue, model_path)\n",
    "    \n",
    "    # Start both systems\n",
    "    audio_processor.start_processing()\n",
    "    recognizer.start_recognition()\n",
    "    \n",
    "    try:\n",
    "        print(\"Say something (running for 15 seconds)...\")\n",
    "        # Run for a while to test\n",
    "        time.sleep(15)\n",
    "    finally:\n",
    "        # Stop everything\n",
    "        recognizer.stop_recognition()\n",
    "        audio_processor.stop_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14fac6",
   "metadata": {},
   "source": [
    "### Exercise 4: Implement a Threaded Understanding Manager\n",
    "\n",
    "1. Create a Python file called `threaded_understanding.py`\n",
    "2. Implement a class that:\n",
    "   - Takes recognized text from a queue\n",
    "   - Processes it to extract intents and entities\n",
    "   - Maintains conversation context across turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "import re\n",
    "import time\n",
    "\n",
    "class ThreadedUnderstanding:\n",
    "    def __init__(self, text_queue):\n",
    "        \"\"\"Initialize the threaded understanding manager.\n",
    "        \n",
    "        Args:\n",
    "            text_queue: Queue containing recognized text to process\n",
    "        \"\"\"\n",
    "        # Store the text queue\n",
    "        self.text_queue = text_queue\n",
    "        \n",
    "        # Create an output queue for intents and entities\n",
    "        self.intent_queue = queue.Queue()\n",
    "        \n",
    "        # Thread control flags\n",
    "        self.is_running = False\n",
    "        self.understanding_thread = None\n",
    "        \n",
    "        # Initialize intent patterns\n",
    "        self.intent_patterns = {\n",
    "            \"greeting\": [\n",
    "                r\"(hello|hi|hey|greetings)( there| assistant| voice assistant)?\",\n",
    "                r\"good (morning|afternoon|evening)\"\n",
    "            ],\n",
    "            \"farewell\": [\n",
    "                r\"(goodbye|bye|see you( later)?)\",\n",
    "                r\"(exit|quit|stop)( assistant| program)?\"\n",
    "            ],\n",
    "            \"weather_inquiry\": [\n",
    "                r\"(what|how)('s| is) (the )?weather( like)?( in (?P<location>\\w+))?\",\n",
    "                r\"(weather|forecast)( in| for) (?P<location>[\\w\\s]+)\"\n",
    "            ],\n",
    "            \"time_inquiry\": [\n",
    "                r\"what('s| is) (the )?time( now)?\",\n",
    "                r\"(tell|give) me the (current |)time\"\n",
    "            ],\n",
    "            \"device_control\": [\n",
    "                r\"(turn|switch) (?P<action>on|off) (the )?(?P<device>[\\w\\s]+)( please)?\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Initialize context\n",
    "        self.context = {\n",
    "            \"last_intent\": None,\n",
    "            \"entities\": {},\n",
    "            \"conversation_history\": []\n",
    "        }\n",
    "        \n",
    "    def start_understanding(self):\n",
    "        \"\"\"Start the understanding process in a background thread.\"\"\"\n",
    "        if self.understanding_thread is not None and self.understanding_thread.is_alive():\n",
    "            print(\"Understanding process already running!\")\n",
    "            return\n",
    "            \n",
    "        # Create and start the thread\n",
    "        self.is_running = True\n",
    "        self.understanding_thread = threading.Thread(target=self.understanding_thread_func)\n",
    "        self.understanding_thread.daemon = True\n",
    "        self.understanding_thread.start()\n",
    "        print(\"Speech understanding started.\")\n",
    "        \n",
    "    def understanding_thread_func(self):\n",
    "        \"\"\"The main understanding thread function.\"\"\"\n",
    "        try:\n",
    "            while self.is_running:\n",
    "                try:\n",
    "                    # Get text data with timeout\n",
    "                    text_data = self.text_queue.get(timeout=0.5)\n",
    "                    \n",
    "                    # Only process final results\n",
    "                    if text_data[\"type\"] == \"final\":\n",
    "                        text = text_data[\"text\"]\n",
    "                        \n",
    "                        # Process the text\n",
    "                        intent, entities = self.detect_intent(text)\n",
    "                        \n",
    "                        # Handle context\n",
    "                        intent, entities = self.apply_context(intent, entities, text)\n",
    "                        \n",
    "                        # Update context\n",
    "                        self.update_context(intent, entities, text)\n",
    "                        \n",
    "                        # Add to output queue\n",
    "                        self.intent_queue.put({\n",
    "                            \"intent\": intent,\n",
    "                            \"entities\": entities,\n",
    "                            \"text\": text\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"Intent: {intent}, Entities: {entities}\")\n",
    "                    \n",
    "                    # Mark task as done\n",
    "                    self.text_queue.task_done()\n",
    "                    \n",
    "                except queue.Empty:\n",
    "                    # No text data available, just continue\n",
    "                    pass\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing text: {str(e)}\")\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "            print(\"Understanding thread stopping...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in understanding thread: {str(e)}\")\n",
    "            \n",
    "    def detect_intent(self, text):\n",
    "        \"\"\"\n",
    "        Detect the intent from the given text.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            A tuple of (intent, entities) where entities is a dictionary\n",
    "        \"\"\"\n",
    "        # Convert text to lowercase for case-insensitive matching\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Check each intent and its patterns\n",
    "        for intent, patterns in self.intent_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, text)\n",
    "                if match:\n",
    "                    # Extract entities from the match\n",
    "                    entities = self._extract_entities(intent, match, text)\n",
    "                    return intent, entities\n",
    "        \n",
    "        # No match found, return unknown intent\n",
    "        return \"unknown\", {}\n",
    "        \n",
    "    def _extract_entities(self, intent, match, text):\n",
    "        \"\"\"Extract entities from the regex match.\"\"\"\n",
    "        entities = {}\n",
    "        \n",
    "        # Extract named groups from the regex match\n",
    "        for group_name in match.groupdict():\n",
    "            entities[group_name] = match.group(group_name)\n",
    "            \n",
    "        # Special handling for certain intents\n",
    "        if intent == \"weather_inquiry\" and \"location\" not in entities:\n",
    "            # Try to extract location after \"in\"\n",
    "            location_match = re.search(r\"in (?P<location>[\\w\\s]+)$\", text.lower())\n",
    "            if location_match:\n",
    "                entities[\"location\"] = location_match.group(\"location\").strip()\n",
    "                \n",
    "        return entities\n",
    "        \n",
    "    def apply_context(self, intent, entities, text):\n",
    "        \"\"\"Apply context to handle ambiguous queries.\"\"\"\n",
    "        # If this is an unknown intent, see if we can use context\n",
    "        if intent == \"unknown\":\n",
    "            last_intent = self.context.get(\"last_intent\")\n",
    "            \n",
    "            # Handle follow-up queries about weather\n",
    "            if last_intent == \"weather_inquiry\":\n",
    "                # Look for time references\n",
    "                if any(word in text.lower() for word in [\"tomorrow\", \"later\", \"weekend\"]):\n",
    "                    # This is likely a follow-up about weather\n",
    "                    intent = \"weather_inquiry\"\n",
    "                    entities[\"location\"] = self.context[\"entities\"].get(\"location\", \"current location\")\n",
    "                    \n",
    "                    # Extract time reference\n",
    "                    if \"tomorrow\" in text.lower():\n",
    "                        entities[\"time\"] = \"tomorrow\"\n",
    "                    elif \"weekend\" in text.lower():\n",
    "                        entities[\"time\"] = \"this weekend\"\n",
    "                    else:\n",
    "                        entities[\"time\"] = \"later\"\n",
    "        \n",
    "        return intent, entities\n",
    "        \n",
    "    def update_context(self, intent, entities, text):\n",
    "        \"\"\"Update the conversation context.\"\"\"\n",
    "        # Update last intent\n",
    "        self.context[\"last_intent\"] = intent\n",
    "        \n",
    "        # Update entities (only add new ones, don't remove existing)\n",
    "        for key, value in entities.items():\n",
    "            self.context[\"entities\"][key] = value\n",
    "            \n",
    "        # Add to conversation history\n",
    "        self.context[\"conversation_history\"].append({\n",
    "            \"text\": text,\n",
    "            \"intent\": intent,\n",
    "            \"entities\": entities.copy(),\n",
    "            \"timestamp\": time.time()\n",
    "        })\n",
    "        \n",
    "        # Trim history if too long\n",
    "        if len(self.context[\"conversation_history\"]) > 10:\n",
    "            self.context[\"conversation_history\"] = self.context[\"conversation_history\"][-10:]\n",
    "            \n",
    "    def stop_understanding(self):\n",
    "        \"\"\"Stop the understanding process.\"\"\"\n",
    "        print(\"Stopping speech understanding...\")\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Wait for thread to finish\n",
    "        if self.understanding_thread and self.understanding_thread.is_alive():\n",
    "            self.understanding_thread.join(timeout=2.0)\n",
    "            \n",
    "        print(\"Speech understanding stopped.\")\n",
    "        \n",
    "    def get_intent_queue(self):\n",
    "        \"\"\"Get the queue that contains detected intents.\"\"\"\n",
    "        return self.intent_queue\n",
    "\n",
    "# Test the understanding system\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a test queue\n",
    "    text_queue = queue.Queue()\n",
    "    \n",
    "    # Create the understanding system\n",
    "    understanding = ThreadedUnderstanding(text_queue)\n",
    "    \n",
    "    # Start the system\n",
    "    understanding.start_understanding()\n",
    "    \n",
    "    try:\n",
    "        # Put some test phrases in the queue\n",
    "        test_phrases = [\n",
    "            \"hello there\",\n",
    "            \"what's the weather like today\",\n",
    "            \"what's the weather like in New York\",\n",
    "            \"what time is it\",\n",
    "            \"turn on the living room lights\",\n",
    "            \"how about tomorrow\"\n",
    "        ]\n",
    "        \n",
    "        for phrase in test_phrases:\n",
    "            print(f\"\\nTesting phrase: '{phrase}'\")\n",
    "            text_queue.put({\"type\": \"final\", \"text\": phrase})\n",
    "            time.sleep(1)  # Give time for processing\n",
    "            \n",
    "    finally:\n",
    "        understanding.stop_understanding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30255f54",
   "metadata": {},
   "source": [
    "### Exercise 5: Create the Integrated System\n",
    "\n",
    "Now, create a main file called `voice_assistant.py` that integrates all the components:\n",
    "\n",
    "1. The ThreadedAudioProcessor for audio capture\n",
    "2. The ThreadedRecognition for speech-to-text\n",
    "3. The ThreadedUnderstanding for intent detection\n",
    "4. A response generator and action executor\n",
    "\n",
    "This will create a complete, integrated voice assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c480c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Import our components\n",
    "# Note: In a real project, these would be imported from their respective files\n",
    "from threaded_audio_processor import ThreadedAudioProcessor\n",
    "from threaded_recognition import ThreadedRecognition\n",
    "from threaded_understanding import ThreadedUnderstanding\n",
    "\n",
    "class ResponseGenerator:\n",
    "    \"\"\"Generates responses based on intents and entities.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize response templates.\"\"\"\n",
    "        self.response_templates = {\n",
    "            \"greeting\": [\n",
    "                \"Hello! How can I help you today?\",\n",
    "                \"Hi there! What can I do for you?\",\n",
    "                \"Greetings! How may I assist you?\"\n",
    "            ],\n",
    "            \"farewell\": [\n",
    "                \"Goodbye! Have a great day!\",\n",
    "                \"See you later!\",\n",
    "                \"Bye for now!\"\n",
    "            ],\n",
    "            \"weather_inquiry\": [\n",
    "                \"The weather in {location} is {condition} with a temperature of {temp}°F.\",\n",
    "                \"In {location}, it's {condition} and {temp}°F.\",\n",
    "                \"The forecast for {location} shows {condition} conditions and {temp}°F.\"\n",
    "            ],\n",
    "            \"time_inquiry\": [\n",
    "                \"The current time is {time}.\",\n",
    "                \"It's {time} right now.\",\n",
    "                \"The time is {time}.\"\n",
    "            ],\n",
    "            \"device_control\": [\n",
    "                \"I've turned {action} the {device}.\",\n",
    "                \"The {device} is now {action}.\",\n",
    "                \"{device} turned {action}.\"\n",
    "            ],\n",
    "            \"unknown\": [\n",
    "                \"I'm not sure I understand. Can you rephrase that?\",\n",
    "                \"I don't know how to help with that yet.\",\n",
    "                \"I didn't quite catch that. What would you like me to do?\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def generate_response(self, intent, entities):\n",
    "        \"\"\"Generate a response based on intent and entities.\"\"\"\n",
    "        # If we don't have templates for this intent, use unknown\n",
    "        if intent not in self.response_templates:\n",
    "            intent = \"unknown\"\n",
    "            \n",
    "        # Get a random template for this intent\n",
    "        templates = self.response_templates[intent]\n",
    "        template = random.choice(templates)\n",
    "        \n",
    "        # For specific intents, add mock data\n",
    "        if intent == \"weather_inquiry\":\n",
    "            # Mock weather data\n",
    "            entities[\"location\"] = entities.get(\"location\", \"current location\")\n",
    "            entities[\"condition\"] = random.choice([\"sunny\", \"cloudy\", \"rainy\", \"clear\"])\n",
    "            entities[\"temp\"] = random.randint(65, 85)\n",
    "            \n",
    "        elif intent == \"time_inquiry\":\n",
    "            # Real time\n",
    "            entities[\"time\"] = time.strftime(\"%I:%M %p\")\n",
    "            \n",
    "        # Format the template with entities\n",
    "        try:\n",
    "            return template.format(**entities)\n",
    "        except KeyError:\n",
    "            # If we're missing required entities, return a fallback\n",
    "            return \"I need more information to help with that.\"\n",
    "\n",
    "\n",
    "class ActionExecutor:\n",
    "    \"\"\"Executes actions based on intents and entities.\"\"\"\n",
    "    \n",
    "    def execute_action(self, intent, entities):\n",
    "        \"\"\"Execute an action based on intent and entities.\"\"\"\n",
    "        if intent == \"device_control\":\n",
    "            device = entities.get(\"device\", \"unknown device\")\n",
    "            action = entities.get(\"action\", \"unknown action\")\n",
    "            print(f\"[Action] Turning {action} {device}\")\n",
    "            return True\n",
    "            \n",
    "        elif intent == \"weather_inquiry\":\n",
    "            location = entities.get(\"location\", \"current location\")\n",
    "            print(f\"[Action] Looking up weather for {location}\")\n",
    "            return True\n",
    "            \n",
    "        # No action for other intents\n",
    "        return False\n",
    "\n",
    "\n",
    "class VoiceAssistant:\n",
    "    \"\"\"Main voice assistant class that integrates all components.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize the voice assistant.\"\"\"\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        # Create component instances\n",
    "        self.audio_processor = ThreadedAudioProcessor()\n",
    "        self.audio_queue = self.audio_processor.get_audio_queue()\n",
    "        \n",
    "        self.recognizer = ThreadedRecognition(self.audio_queue, self.model_path)\n",
    "        self.text_queue = self.recognizer.get_text_queue()\n",
    "        \n",
    "        self.understanding = ThreadedUnderstanding(self.text_queue)\n",
    "        self.intent_queue = self.understanding.get_intent_queue()\n",
    "        \n",
    "        self.response_generator = ResponseGenerator()\n",
    "        self.action_executor = ActionExecutor()\n",
    "        \n",
    "        # Thread control\n",
    "        self.is_running = False\n",
    "        self.response_thread = None\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start the voice assistant.\"\"\"\n",
    "        if self.is_running:\n",
    "            print(\"Voice assistant is already running!\")\n",
    "            return\n",
    "            \n",
    "        print(\"Starting voice assistant...\")\n",
    "        \n",
    "        # Start all components\n",
    "        self.audio_processor.start_processing()\n",
    "        self.recognizer.start_recognition()\n",
    "        self.understanding.start_understanding()\n",
    "        \n",
    "        # Start response thread\n",
    "        self.is_running = True\n",
    "        self.response_thread = threading.Thread(target=self.response_thread_func)\n",
    "        self.response_thread.daemon = True\n",
    "        self.response_thread.start()\n",
    "        \n",
    "        print(\"Voice assistant is now listening. Speak clearly!\")\n",
    "        \n",
    "    def response_thread_func(self):\n",
    "        \"\"\"Thread that generates responses and executes actions.\"\"\"\n",
    "        try:\n",
    "            while self.is_running:\n",
    "                try:\n",
    "                    # Get intent data with timeout\n",
    "                    intent_data = self.intent_queue.get(timeout=0.5)\n",
    "                    \n",
    "                    intent = intent_data[\"intent\"]\n",
    "                    entities = intent_data[\"entities\"]\n",
    "                    \n",
    "                    # Generate response\n",
    "                    response = self.response_generator.generate_response(intent, entities)\n",
    "                    \n",
    "                    # Execute action\n",
    "                    self.action_executor.execute_action(intent, entities)\n",
    "                    \n",
    "                    # Print response\n",
    "                    print(f\"\\nAssistant: {response}\")\n",
    "                    \n",
    "                    # Mark task as done\n",
    "                    self.intent_queue.task_done()\n",
    "                    \n",
    "                except queue.Empty:\n",
    "                    # No intent data available, just continue\n",
    "                    pass\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in response thread: {str(e)}\")\n",
    "            \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the voice assistant.\"\"\"\n",
    "        if not self.is_running:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nStopping voice assistant...\")\n",
    "        self.is_running = False\n",
    "        \n",
    "        # Stop all components\n",
    "        self.understanding.stop_understanding()\n",
    "        self.recognizer.stop_recognition()\n",
    "        self.audio_processor.stop_processing()\n",
    "        \n",
    "        # Wait for response thread\n",
    "        if self.response_thread and self.response_thread.is_alive():\n",
    "            self.response_thread.join(timeout=2.0)\n",
    "            \n",
    "        print(\"Voice assistant stopped.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the voice assistant.\"\"\"\n",
    "    # Path to your Vosk model\n",
    "    model_path = \"/home/luar/AI/voice_assistant/vosk-model-small-en-us-0.15\"\n",
    "    \n",
    "    # Check if model exists\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: Model not found at {model_path}\")\n",
    "        print(\"Please download a model from https://alphacephei.com/vosk/models\")\n",
    "        return\n",
    "    \n",
    "    # Create and start the voice assistant\n",
    "    assistant = VoiceAssistant(model_path)\n",
    "    \n",
    "    try:\n",
    "        # Start the assistant\n",
    "        assistant.start()\n",
    "        \n",
    "        # Keep running until interrupted\n",
    "        print(\"Press Ctrl+C to exit\")\n",
    "        while True:\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted by user\")\n",
    "        \n",
    "    finally:\n",
    "        # Stop the assistant\n",
    "        assistant.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6b7ee",
   "metadata": {},
   "source": [
    "## CHALLENGES AND EXTENSIONS\n",
    "\n",
    "1. **Add Wake Word Detection**: Modify the system to only process speech when triggered by a wake word like \"Hey Assistant\".\n",
    "\n",
    "2. **Text-to-Speech Response**: Add a module that converts the assistant's text responses to speech using a TTS library.\n",
    "\n",
    "3. **Error Recovery**: Improve error handling to make the system more robust against errors in any component.\n",
    "\n",
    "4. **Performance Optimization**: Profile the system to identify bottlenecks and optimize resource usage.\n",
    "\n",
    "5. **Voice Activity Detection**: Add VAD to process audio only when speech is detected.\n",
    "\n",
    "6. **Multiple Intent Support**: Enhance the understanding system to handle multiple intents in a single utterance.\n",
    "\n",
    "## CONCLUSION\n",
    "\n",
    "You've now built an integrated voice assistant system that combines real-time speech recognition with natural language understanding. This foundation can be extended with additional capabilities like wake word detection, text-to-speech, and more sophisticated understanding.\n",
    "\n",
    "In the next module, we'll build on this integration to create a complete voice assistant project that can perform useful tasks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
