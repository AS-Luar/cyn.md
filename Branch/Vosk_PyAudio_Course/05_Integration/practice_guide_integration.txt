# PRACTICE GUIDE: INTEGRATION OF SPEECH RECOGNITION AND UNDERSTANDING

## OVERVIEW

In this practice session, you will integrate the speech recognition and speech understanding components developed in previous modules to create a cohesive system. This integration will form the foundation for a complete voice assistant.

## OBJECTIVES

1. Design a modular architecture for the voice assistant
2. Implement threaded processing for concurrent operations
3. Create a pipeline for audio capture → speech recognition → intent understanding
4. Develop a responsive feedback system

## PREREQUISITES

- Completion of Modules 1-4
- Understanding of basic threading concepts in Python
- Familiarity with the queue module

## PRACTICE EXERCISES

### Exercise 1: Design the System Architecture

1. Draw a diagram (on paper or using a digital tool) that illustrates:
   - Components of the system (audio capture, recognition, understanding)
   - Data flow between components
   - Threading model
   - User feedback mechanisms
   
2. Document your architecture with comments explaining:
   - How components will communicate
   - How to manage processing load
   - Error handling approach

### Exercise 2: Implement a Threaded Audio Processor

1. Create a new Python file called `threaded_audio_processor.py`
2. Implement a class that:
   - Captures audio in a background thread
   - Processes audio frames as they become available
   - Uses a queue to pass audio data to the recognition component
   - Can be started and stopped cleanly

```python
import threading
import queue
import pyaudio
import time

class ThreadedAudioProcessor:
    def __init__(self):
        # TODO: Initialize necessary components
        # 1. Create a queue for audio frames
        # 2. Set up PyAudio
        # 3. Create thread control flags
        pass
        
    def start_processing(self):
        # TODO: Start the audio processing thread
        pass
        
    def process_audio_thread(self):
        # TODO: Implement the main audio processing loop
        # 1. Open audio stream
        # 2. Read frames and add to queue
        # 3. Properly handle clean shutdown
        pass
        
    def stop_processing(self):
        # TODO: Implement clean shutdown
        pass
```

### Exercise 3: Create a Threaded Recognition System

1. Create a Python file called `threaded_recognition.py`
2. Implement a class that:
   - Takes audio frames from a queue
   - Processes them with Vosk in a separate thread
   - Outputs recognized text to another queue

```python
from vosk import Model, KaldiRecognizer
import queue
import json
import threading

class ThreadedRecognition:
    def __init__(self, audio_queue, model_path):
        # TODO: Initialize the recognition components
        # 1. Store the audio queue
        # 2. Create a text output queue
        # 3. Load the Vosk model
        # 4. Set up thread control flags
        pass
        
    def start_recognition(self):
        # TODO: Start the recognition thread
        pass
        
    def recognition_thread(self):
        # TODO: Implement the main recognition loop
        # 1. Get audio frames from queue
        # 2. Process with Vosk
        # 3. Output recognized text to result queue
        pass
        
    def stop_recognition(self):
        # TODO: Implement clean shutdown
        pass
```

### Exercise 4: Create an Intent Processing Component

1. Create a Python file called `intent_processor.py`
2. Implement a class that:
   - Takes recognized text from a queue
   - Processes it to identify intents and entities
   - Performs appropriate actions based on detected intents

```python
import threading
import queue
import re
import json

class IntentProcessor:
    def __init__(self, text_queue):
        # TODO: Initialize the intent processor
        # 1. Store the text queue
        # 2. Define intent patterns
        # 3. Set up thread control flags
        pass
        
    def start_processing(self):
        # TODO: Start the intent processing thread
        pass
        
    def processing_thread(self):
        # TODO: Implement the main processing loop
        # 1. Get text from queue
        # 2. Identify intents and entities
        # 3. Take appropriate actions
        pass
        
    def stop_processing(self):
        # TODO: Implement clean shutdown
        pass
```

### Exercise 5: Create an Integrated System

1. Create a Python file called `integrated_assistant.py`
2. Implement a class that:
   - Coordinates all the components
   - Handles startup and shutdown of the system
   - Provides user feedback

```python
from threaded_audio_processor import ThreadedAudioProcessor
from threaded_recognition import ThreadedRecognition
from intent_processor import IntentProcessor
import queue
import time

class IntegratedAssistant:
    def __init__(self, model_path):
        # TODO: Initialize the assistant components
        # 1. Create shared queues
        # 2. Initialize all components
        pass
        
    def start(self):
        # TODO: Start all components
        pass
        
    def stop(self):
        # TODO: Stop all components cleanly
        pass
```

### Exercise 6: Test and Refine the System

1. Implement a simple test script that:
   - Starts the integrated system
   - Listens for voice commands
   - Prints detected intents and responses
   - Stops on a specific command or after a timeout

2. Test with various commands and document:
   - Response time
   - Recognition accuracy
   - Any issues encountered

## EXPECTED OUTCOMES

By completing these exercises, you'll have created:

1. A threaded audio processing system
2. A concurrent speech recognition component
3. A real-time intent processing system
4. An integrated assistant framework

## SUBMISSION GUIDELINES

1. Submit your completed Python files
2. Include comments explaining your implementation choices
3. Document any challenges faced and how you overcame them
4. Suggest potential improvements for the system

## NEXT STEPS

After completing this practice session, you'll be ready to build a complete voice assistant in Module 6, adding more capabilities and refining the user experience.
