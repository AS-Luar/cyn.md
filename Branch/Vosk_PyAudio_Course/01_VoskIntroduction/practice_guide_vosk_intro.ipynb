{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e360f91f",
   "metadata": {},
   "source": [
    "# VOSK INTRODUCTION PRACTICE GUIDE\n",
    "\n",
    "## EXERCISE GOAL\n",
    "In this practice session, you'll install Vosk, download a language model, and create a simple program that recognizes speech from a pre-recorded WAV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ac332",
   "metadata": {},
   "source": [
    "## STEP-BY-STEP INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b628999",
   "metadata": {},
   "source": [
    "### Step 1: Install Vosk Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5331aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Vosk package and SoundFile\n",
    "!pip install vosk soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21123cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model\n",
    "print('Vosk installed successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f05a6",
   "metadata": {},
   "source": [
    "### Step 2: Download a Vosk Model\n",
    "- Visit https://alphacephei.com/vosk/models\n",
    "- Download the appropriate model for your language (we recommend starting with a small model)\n",
    "- For English, you can use: vosk-model-small-en-us-0.15\n",
    "\n",
    "You can download and extract the model automatically using the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Create models directory\n",
    "!mkdir -p models\n",
    "\n",
    "# Check if the model is already downloaded\n",
    "model_dir = \"models/vosk-model-small-en-us-0.15\"\n",
    "if not os.path.exists(model_dir):\n",
    "    # Download model (US English small)\n",
    "    !wget -P models https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
    "    \n",
    "    # Unzip the model\n",
    "    !unzip -q models/vosk-model-small-en-us-0.15.zip -d models\n",
    "    \n",
    "    print(\"Model downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Model already exists. Using existing model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de364df",
   "metadata": {},
   "source": [
    "### Step 3: Create a Test Audio File\n",
    "\n",
    "We need an audio file for testing. If you already have one, you can use that. Otherwise, let's create a simple function to record audio using PyAudio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0677b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib conf.c:5694:(snd_config_expand) Unknown parameters {AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2 CARD 0}\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM iec958:{AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2 CARD 0}\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 5 seconds...\n",
      "Recording finished.\n",
      "Audio saved to test.wav\n",
      "Recording finished.\n",
      "Audio saved to test.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(filename=\"test.wav\", seconds=5, sample_rate=44000):\n",
    "    \"\"\"Record audio from microphone and save to WAV file\"\"\"\n",
    "    # Configure PyAudio\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=sample_rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=1024)\n",
    "    \n",
    "    print(f\"Recording for {seconds} seconds...\")\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    # Record audio\n",
    "    for i in range(0, int(sample_rate / 1024 * seconds)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "        \n",
    "    print(\"Recording finished.\")\n",
    "    \n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    # Save the recorded audio as a WAV file\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    print(f\"Audio saved to {filename}\")\n",
    "    return filename\n",
    "\n",
    "test_file = record_audio(seconds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e0fc9",
   "metadata": {},
   "source": [
    "### Step 4: Build the Speech Recognition Function\n",
    "\n",
    "Now, let's create a function to recognize speech from an audio file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a2b70",
   "metadata": {},
   "source": [
    "#### What is KaldiRecognizer?\n",
    "\n",
    "`KaldiRecognizer` is a class provided by the Vosk library that performs speech recognition using a pre-trained model. It processes audio data and converts spoken words into text. Internally, it uses the Kaldi speech recognition toolkit, which is a powerful open-source toolkit for speech recognition research. In Vosk, `KaldiRecognizer` handles the decoding of audio streams and provides recognized text results as you feed it audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "import os\n",
    "\n",
    "def recognize_speech(audio_file=\"test.wav\", model_path=\"./vosk-model-small-en-us-0.15\"):\n",
    "    \"\"\"Recognize speech from audio file using Vosk\"\"\"\n",
    "    # Validate model path\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Error: Model not found at {model_path}\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Validate audio file\n",
    "    if not os.path.exists(audio_file):\n",
    "        print(f\"Error: Audio file not found at {audio_file}\")\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Load the model\n",
    "    model = Model(model_path)\n",
    "    \n",
    "    # Open the audio file\n",
    "    wf = wave.open(audio_file, \"rb\")\n",
    "    \n",
    "    # Check audio format\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        print(\"Audio file must be WAV format mono PCM.\")\n",
    "        return \"\"\n",
    "    \n",
    "    # Create a recognizer\n",
    "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "    \n",
    "    # Process the audio\n",
    "    text = \"\"\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            partial_text = result.get(\"text\", \"\")\n",
    "            text += partial_text + \" \"\n",
    "            print(f\"Partial: {partial_text}\")\n",
    "    \n",
    "    # Get the final result\n",
    "    final_result = json.loads(recognizer.FinalResult())\n",
    "    final_text = final_result.get(\"text\", \"\")\n",
    "    text += final_text\n",
    "    print(f\"Final: {final_text}\")\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Example usage:\n",
    "# recognized_text = recognize_speech(\"test.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97b38d",
   "metadata": {},
   "source": [
    "#### Line-by-line Explanation of the recognize_speech Function\n",
    "\n",
    "- `from vosk import Model, KaldiRecognizer`  \n",
    "  Imports the Vosk classes needed for loading the speech model and performing recognition.\n",
    "\n",
    "- `import json`  \n",
    "  Imports the JSON module to parse recognition results, which are returned as JSON strings.\n",
    "\n",
    "- `import os`  \n",
    "  Imports the OS module to check if files and directories exist.\n",
    "\n",
    "- `def recognize_speech(audio_file=\"test.wav\", model_path=\"models/vosk-model-small-en-us-0.15\"):`  \n",
    "  Defines a function that takes the path to an audio file and a model directory.\n",
    "\n",
    "- `if not os.path.exists(model_path):`  \n",
    "  Checks if the model directory exists.\n",
    "\n",
    "- `print(f\"Error: Model not found at {model_path}\")`  \n",
    "  Prints an error if the model directory is missing.\n",
    "\n",
    "- `return \"\"`  \n",
    "  Stops the function and returns an empty string if the model is missing.\n",
    "\n",
    "- `if not os.path.exists(audio_file):`  \n",
    "  Checks if the audio file exists.\n",
    "\n",
    "- `print(f\"Error: Audio file not found at {audio_file}\")`  \n",
    "  Prints an error if the audio file is missing.\n",
    "\n",
    "- `return \"\"`  \n",
    "  Stops the function and returns an empty string if the audio file is missing.\n",
    "\n",
    "- `model = Model(model_path)`  \n",
    "  Loads the Vosk model from the specified directory.\n",
    "\n",
    "- `wf = wave.open(audio_file, \"rb\")`  \n",
    "  Opens the audio file for reading in binary mode.\n",
    "\n",
    "- `if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":`  \n",
    "  Checks if the audio file is mono, 16-bit, and uncompressed PCM format.\n",
    "\n",
    "- `print(\"Audio file must be WAV format mono PCM.\")`  \n",
    "  Prints an error if the audio file format is not supported.\n",
    "\n",
    "- `return \"\"`  \n",
    "  Stops the function and returns an empty string if the format is wrong.\n",
    "\n",
    "- `recognizer = KaldiRecognizer(model, wf.getframerate())`  \n",
    "  Creates a KaldiRecognizer object using the model and the audio file's sample rate.\n",
    "\n",
    "- `text = \"\"`  \n",
    "  Initializes an empty string to store recognized text.\n",
    "\n",
    "- `while True:`  \n",
    "  Starts a loop to process the audio in chunks.\n",
    "\n",
    "- `data = wf.readframes(4000)`  \n",
    "  Reads 4000 frames of audio data from the file.\n",
    "\n",
    "- `if len(data) == 0:`  \n",
    "  Checks if there is no more data to read.\n",
    "\n",
    "- `break`  \n",
    "  Exits the loop if all audio has been processed.\n",
    "\n",
    "- `if recognizer.AcceptWaveform(data):`  \n",
    "  Feeds the audio chunk to the recognizer and checks if a full utterance has been recognized.\n",
    "\n",
    "- `result = json.loads(recognizer.Result())`  \n",
    "  Gets the recognition result as a JSON string and parses it into a Python dictionary.\n",
    "\n",
    "- `partial_text = result.get(\"text\", \"\")`  \n",
    "  Extracts the recognized text from the result.\n",
    "\n",
    "- `text += partial_text + \" \"`  \n",
    "  Adds the recognized text to the output string.\n",
    "\n",
    "- `print(f\"Partial: {partial_text}\")`  \n",
    "  Prints the partial result for debugging.\n",
    "\n",
    "- `final_result = json.loads(recognizer.FinalResult())`  \n",
    "  Gets the final recognition result after all audio is processed.\n",
    "\n",
    "- `final_text = final_result.get(\"text\", \"\")`  \n",
    "  Extracts the final recognized text.\n",
    "\n",
    "- `text += final_text`  \n",
    "  Adds the final recognized text to the output string.\n",
    "\n",
    "- `print(f\"Final: {final_text}\")`  \n",
    "  Prints the final result.\n",
    "\n",
    "- `return text.strip()`  \n",
    "  Returns the complete recognized text, with leading/trailing spaces removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd388bf",
   "metadata": {},
   "source": [
    "### Step 5: Test the Speech Recognition\n",
    "\n",
    "Now let's bring everything together! You can record audio and then recognize the speech, or use an existing audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c647e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Record new audio and recognize\n",
    "def record_and_recognize(duration=5):\n",
    "    audio_file = record_audio(seconds=duration)\n",
    "    return recognize_speech(audio_file)\n",
    "\n",
    "# Option 2: Recognize speech from an existing file\n",
    "def recognize_from_file(file_path):\n",
    "    return recognize_speech(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f9c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment one of the following options:\n",
    "\n",
    "# Option 1: Record and recognize\n",
    "# text = record_and_recognize(5)\n",
    "# print(f\"\\nRecognized text: {text}\")\n",
    "\n",
    "# Option 2: Use an existing file\n",
    "# existing_file = \"/path/to/your/audio.wav\"  # Replace with your audio file path\n",
    "# text = recognize_from_file(existing_file)\n",
    "# print(f\"\\nRecognized text: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba4c1b",
   "metadata": {},
   "source": [
    "### Step 6: Experiment and Learn\n",
    "\n",
    "Now that you have a working speech recognition system, try experimenting with it:\n",
    "\n",
    "1. Record audio with different content and see how well it's recognized\n",
    "2. Try modifying the code to handle longer recordings\n",
    "3. Explore how different audio quality affects recognition accuracy\n",
    "\n",
    "Below is a space for your experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb86075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimentation code here\n",
    "# Ideas:\n",
    "# - Measure recognition accuracy with different audio inputs\n",
    "# - Process an audio file with background noise\n",
    "# - Add timing measurements to check performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9deeeb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've successfully installed Vosk, set up a language model, and created a program that can recognize speech from audio files. This is a fundamental building block for your voice assistant project.\n",
    "\n",
    "In the next modules, you'll learn about audio preprocessing techniques that can improve recognition accuracy, especially in noisy environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
